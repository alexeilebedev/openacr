//
// include/gen/kafka_gen.h
// Generated by AMC
//
// Copyright (C) 2008-2013 AlgoEngineering LLC
// Copyright (C) 2013-2019 NYSE | Intercontinental Exchange
// Copyright (C) 2020-2023 Astra
// Copyright (C) 2023 AlgoRND
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.
//


#pragma once
#include "include/gen/algo_gen.h"
//#pragma endinclude
// gen:ns_enums

// --- kafka_AclOperationTypeEnum

enum kafka_AclOperationTypeEnum {                    // kafka.AclOperationType.value
     kafka_AclOperationType_UNKNOWN            = 0
    ,kafka_AclOperationType_ANY                = 1
    ,kafka_AclOperationType_ALL                = 2
    ,kafka_AclOperationType_READ               = 3
    ,kafka_AclOperationType_WRITE              = 4
    ,kafka_AclOperationType_CREATE             = 5
    ,kafka_AclOperationType_DELETE             = 6
    ,kafka_AclOperationType_ALTER              = 7
    ,kafka_AclOperationType_DESCRIBE           = 8
    ,kafka_AclOperationType_CLUSTER_ACTION     = 9
    ,kafka_AclOperationType_DESCRIBE_CONFIGS   = 10
    ,kafka_AclOperationType_ALTER_CONFIGS      = 11
    ,kafka_AclOperationType_IDEMPOTENT_WRITE   = 12
    ,kafka_AclOperationType_CREATE_TOKENS      = 13
    ,kafka_AclOperationType_DESCRIBE_TOKENS    = 14
};

enum { kafka_AclOperationTypeEnum_N = 15 };


// --- kafka_AclOperationsEnum

enum kafka_AclOperationsEnum {                             // kafka.AclOperations.value
     kafka_AclOperations_UNKNOWN            = 0x1          // kafka.AclOperations.UNKNOWN
    ,kafka_AclOperations_ANY                = 0x2          // kafka.AclOperations.ANY
    ,kafka_AclOperations_ALL                = 0x4          // kafka.AclOperations.ALL
    ,kafka_AclOperations_READ               = 0x8          // kafka.AclOperations.READ
    ,kafka_AclOperations_WRITE              = 0x10         // kafka.AclOperations.WRITE
    ,kafka_AclOperations_CREATE             = 0x20         // kafka.AclOperations.CREATE
    ,kafka_AclOperations_DELETE             = 0x40         // kafka.AclOperations.DELETE
    ,kafka_AclOperations_ALTER              = 0x80         // kafka.AclOperations.ALTER
    ,kafka_AclOperations_DESCRIBE           = 0x100        // kafka.AclOperations.DESCRIBE
    ,kafka_AclOperations_CLUSTER_ACTION     = 0x200        // kafka.AclOperations.CLUSTER_ACTION
    ,kafka_AclOperations_DESCRIBE_CONFIGS   = 0x400        // kafka.AclOperations.DESCRIBE_CONFIGS
    ,kafka_AclOperations_ALTER_CONFIGS      = 0x800        // kafka.AclOperations.ALTER_CONFIGS
    ,kafka_AclOperations_IDEMPOTENT_WRITE   = 0x1000       // kafka.AclOperations.IDEMPOTENT_WRITE
    ,kafka_AclOperations_CREATE_TOKENS      = 0x2000       // kafka.AclOperations.CREATE_TOKENS
    ,kafka_AclOperations_DESCRIBE_TOKENS    = 0x4000       // kafka.AclOperations.DESCRIBE_TOKENS
    ,kafka_AclOperations_OMITTED            = 0x80000000   // kafka.AclOperations.OMITTED
};

enum { kafka_AclOperationsEnum_N = 16 };


// --- kafka_AclPermissionTypeEnum

enum kafka_AclPermissionTypeEnum {          // kafka.AclPermissionType.value
     kafka_AclPermissionType_UNKNOWN   = 0
    ,kafka_AclPermissionType_ANY       = 1
    ,kafka_AclPermissionType_DENY      = 2
    ,kafka_AclPermissionType_ALLOW     = 3
};

enum { kafka_AclPermissionTypeEnum_N = 4 };


// --- kafka_CompressionTypeEnum

enum kafka_CompressionTypeEnum {                 // kafka.CompressionType.value
     kafka_CompressionType_no_compression   = 0
    ,kafka_CompressionType_gzip             = 1
    ,kafka_CompressionType_snappy           = 2
    ,kafka_CompressionType_lz4              = 3
    ,kafka_CompressionType_zstd             = 4
};

enum { kafka_CompressionTypeEnum_N = 5 };


// --- kafka_ConfigSourceEnum

enum kafka_ConfigSourceEnum {                                // kafka.ConfigSource.value
     kafka_ConfigSource_UNKNOWN                         = 0
    ,kafka_ConfigSource_TOPIC_CONFIG                    = 1
    ,kafka_ConfigSource_DYNAMIC_BROKER_CONFIG           = 2
    ,kafka_ConfigSource_DYNAMIC_DEFAULT_BROKER_CONFIG   = 3
    ,kafka_ConfigSource_STATIC_BROKER_CONFIG            = 4
    ,kafka_ConfigSource_DEFAULT_CONFIG                  = 5
    ,kafka_ConfigSource_DYNAMIC_BROKER_LOGGER_CONFIG    = 6
    ,kafka_ConfigSource_CLIENT_METRICS_CONFIG           = 7
    ,kafka_ConfigSource_GROUP_CONFIG                    = 8
};

enum { kafka_ConfigSourceEnum_N = 9 };


// --- kafka_ConfigTypeEnum

enum kafka_ConfigTypeEnum {           // kafka.ConfigType.value
     kafka_ConfigType_UNKNOWN    = 0
    ,kafka_ConfigType_BOOLEAN    = 1
    ,kafka_ConfigType_STRING     = 2
    ,kafka_ConfigType_INT        = 3
    ,kafka_ConfigType_SHORT      = 4
    ,kafka_ConfigType_LONG       = 5
    ,kafka_ConfigType_DOUBLE     = 6
    ,kafka_ConfigType_LIST       = 7
    ,kafka_ConfigType_CLASS      = 8
    ,kafka_ConfigType_PASSWORD   = 9
};

enum { kafka_ConfigTypeEnum_N = 10 };


// --- kafka_FieldIdEnum

enum kafka_FieldIdEnum {                          // kafka.FieldId.value
     kafka_FieldId_value                    = 0
    ,kafka_FieldId_UNKNOWN                  = 1
    ,kafka_FieldId_ANY                      = 2
    ,kafka_FieldId_ALL                      = 3
    ,kafka_FieldId_READ                     = 4
    ,kafka_FieldId_WRITE                    = 5
    ,kafka_FieldId_CREATE                   = 6
    ,kafka_FieldId_DELETE                   = 7
    ,kafka_FieldId_ALTER                    = 8
    ,kafka_FieldId_DESCRIBE                 = 9
    ,kafka_FieldId_CLUSTER_ACTION           = 10
    ,kafka_FieldId_DESCRIBE_CONFIGS         = 11
    ,kafka_FieldId_ALTER_CONFIGS            = 12
    ,kafka_FieldId_IDEMPOTENT_WRITE         = 13
    ,kafka_FieldId_CREATE_TOKENS            = 14
    ,kafka_FieldId_DESCRIBE_TOKENS          = 15
    ,kafka_FieldId_OMITTED                  = 16
    ,kafka_FieldId_key                      = 17
    ,kafka_FieldId_base                     = 18
    ,kafka_FieldId_type                     = 19
    ,kafka_FieldId_version                  = 20
    ,kafka_FieldId_group                    = 21
    ,kafka_FieldId_topic                    = 22
    ,kafka_FieldId_partition                = 23
    ,kafka_FieldId_attributes               = 24
    ,kafka_FieldId_pmask                    = 25
    ,kafka_FieldId_timestamp_delta          = 26
    ,kafka_FieldId_offset_delta             = 27
    ,kafka_FieldId_headers                  = 28
    ,kafka_FieldId_base_offset              = 29
    ,kafka_FieldId_partition_leader_epoch   = 30
    ,kafka_FieldId_magic                    = 31
    ,kafka_FieldId_crc                      = 32
    ,kafka_FieldId_last_offset_delta        = 33
    ,kafka_FieldId_base_timestamp           = 34
    ,kafka_FieldId_max_timestamp            = 35
    ,kafka_FieldId_producer_id              = 36
    ,kafka_FieldId_producer_epoch           = 37
    ,kafka_FieldId_base_sequence            = 38
    ,kafka_FieldId_records                  = 39
};

enum { kafka_FieldIdEnum_N = 40 };


// --- kafka_GroupRecordKeyHeader_type_Enum

enum kafka_GroupRecordKeyHeader_type_Enum {                       // kafka.GroupRecordKeyHeader.type
     kafka_GroupRecordKeyHeader_type_kafka_OffsetCommitKey   = 1
};

enum { kafka_GroupRecordKeyHeader_type_Enum_N = 1 };


// --- kafka_GroupRecordKeyHeaderMsgsCaseEnum

enum kafka_GroupRecordKeyHeaderMsgsCaseEnum {                        // kafka.GroupRecordKeyHeaderMsgsCase.value
     kafka_GroupRecordKeyHeaderMsgsCase_kafka_OffsetCommitKey   = 1
};

enum { kafka_GroupRecordKeyHeaderMsgsCaseEnum_N = 1 };


// --- kafka_GroupRecordValueHeader_type_Enum

enum kafka_GroupRecordValueHeader_type_Enum {                         // kafka.GroupRecordValueHeader.type
     kafka_GroupRecordValueHeader_type_kafka_OffsetCommitValue   = 1
};

enum { kafka_GroupRecordValueHeader_type_Enum_N = 1 };


// --- kafka_GroupRecordValueHeaderMsgsCaseEnum

enum kafka_GroupRecordValueHeaderMsgsCaseEnum {                          // kafka.GroupRecordValueHeaderMsgsCase.value
     kafka_GroupRecordValueHeaderMsgsCase_kafka_OffsetCommitValue   = 1
};

enum { kafka_GroupRecordValueHeaderMsgsCaseEnum_N = 1 };


// --- kafka_GroupStateEnum

enum kafka_GroupStateEnum {                      // kafka.GroupState.value
     kafka_GroupState_Unknown               = 0
    ,kafka_GroupState_PreparingRebalance    = 1
    ,kafka_GroupState_CompletingRebalance   = 2
    ,kafka_GroupState_Stable                = 3
    ,kafka_GroupState_Dead                  = 4
    ,kafka_GroupState_Empty                 = 5
    ,kafka_GroupState_Assigning             = 6
    ,kafka_GroupState_Reconciling           = 7
    ,kafka_GroupState_NotReady              = 8
};

enum { kafka_GroupStateEnum_N = 9 };


// --- kafka_PatternTypeEnum

enum kafka_PatternTypeEnum {            // kafka.PatternType.value
     kafka_PatternType_UNKNOWN    = 0   // Client is too old
    ,kafka_PatternType_ANY        = 1   // In a filter, matches any resource pattern type
    ,kafka_PatternType_MATCH      = 2   // In a filter, pattern matching
    ,kafka_PatternType_LITERAL    = 3   // Literal resource name, or * for any
    ,kafka_PatternType_PREFIXED   = 4   // Prefix for a resource
};

enum { kafka_PatternTypeEnum_N = 5 };


// --- kafka_ResourceTypeEnum

enum kafka_ResourceTypeEnum {                   // kafka.ResourceType.value
     kafka_ResourceType_UNKNOWN            = 0
    ,kafka_ResourceType_ANY                = 1
    ,kafka_ResourceType_TOPIC              = 2
    ,kafka_ResourceType_GROUP              = 3
    ,kafka_ResourceType_CLUSTER            = 4
    ,kafka_ResourceType_TRANSACTIONAL_ID   = 5
    ,kafka_ResourceType_DELEGATION_TOKEN   = 6
    ,kafka_ResourceType_USER               = 7
};

enum { kafka_ResourceTypeEnum_N = 8 };


// --- kafka_TimestampTypeEnum

enum kafka_TimestampTypeEnum {                  // kafka.TimestampType.value
     kafka_TimestampType_create_time       = 0
    ,kafka_TimestampType_log_append_time   = 1
};

enum { kafka_TimestampTypeEnum_N = 2 };

namespace kafka { // gen:ns_pkeytypedef
} // gen:ns_pkeytypedef
namespace kafka { // gen:ns_tclass_field
} // gen:ns_tclass_field
// gen:ns_fwddecl2
namespace kafka { struct GroupRecordKeyHeader; }
namespace kafka { struct GroupRecordValueHeader; }
namespace kafka { struct OffsetCommitKey; }
namespace kafka { struct OffsetCommitValue; }
namespace kafka { struct Frame_payload_curs; }
namespace kafka { struct Record_headers_curs; }
namespace kafka { struct RecordBatch_records_curs; }
namespace kafka { struct AclOperationType; }
namespace kafka { struct AclOperations; }
namespace kafka { struct AclPermissionType; }
namespace kafka { struct CompressionType; }
namespace kafka { struct ConfigSource; }
namespace kafka { struct ConfigType; }
namespace kafka { struct Error; }
namespace kafka { struct FieldId; }
namespace kafka { struct Frame; }
namespace kafka { struct Frame_curs; }
namespace kafka { struct GroupRecordKeyHeaderMsgsCase; }
namespace kafka { struct GroupRecordValueHeaderMsgsCase; }
namespace kafka { struct GroupState; }
namespace kafka { struct Header; }
namespace kafka { struct PatternType; }
namespace kafka { struct Record; }
namespace kafka { struct RecordBatch; }
namespace kafka { struct ResourceType; }
namespace kafka { struct TimestampType; }
namespace kafka { // gen:ns_print_struct

// --- kafka.AclOperationType
#pragma pack(push,1)
struct AclOperationType { // kafka.AclOperationType: AclOperation type
    u8   value;   //   0
    // func:kafka.AclOperationType..Ctor
    inline               AclOperationType() __attribute__((nothrow));
    // func:kafka.AclOperationType..FieldwiseCtor
    explicit inline               AclOperationType(u8 in_value) __attribute__((nothrow));
    // func:kafka.AclOperationType..EnumCtor
    inline               AclOperationType(kafka_AclOperationTypeEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.AclOperationType.value.GetEnum
inline kafka_AclOperationTypeEnum value_GetEnum(const kafka::AclOperationType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.AclOperationType.value.SetEnum
inline void          value_SetEnum(kafka::AclOperationType& parent, kafka_AclOperationTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.AclOperationType.value.ToCstr
const char*          value_ToCstr(const kafka::AclOperationType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.AclOperationType.value.Print
void                 value_Print(const kafka::AclOperationType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.AclOperationType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::AclOperationType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.AclOperationType.value.SetStrptr
void                 value_SetStrptr(kafka::AclOperationType& parent, algo::strptr rhs, kafka_AclOperationTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.AclOperationType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::AclOperationType& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::AclOperationType from an ascii string.
// The format of the string is the format of the kafka::AclOperationType's only field
// func:kafka.AclOperationType..ReadStrptrMaybe
bool                 AclOperationType_ReadStrptrMaybe(kafka::AclOperationType &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.AclOperationType..Init
inline void          AclOperationType_Init(kafka::AclOperationType& parent);
// print string representation of ROW to string STR
// cfmt:kafka.AclOperationType.String  printfmt:Raw
// func:kafka.AclOperationType..Print
void                 AclOperationType_Print(kafka::AclOperationType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.AclOperations
struct AclOperations { // kafka.AclOperations: ACL operations
    i32   value;   //   0
    // func:kafka.AclOperations.value.Cast
    inline               operator kafka_AclOperationsEnum() const __attribute__((nothrow));
    // func:kafka.AclOperations..Ctor
    inline               AclOperations() __attribute__((nothrow));
    // func:kafka.AclOperations..FieldwiseCtor
    explicit inline               AclOperations(i32 in_value) __attribute__((nothrow));
    // func:kafka.AclOperations..EnumCtor
    inline               AclOperations(kafka_AclOperationsEnum arg) __attribute__((nothrow));
};

// Retrieve bitfield from value of field value
//    1 bits starting at bit 0.
// func:kafka.AclOperations.UNKNOWN.Get
inline bool          UNKNOWN_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 0.
// func:kafka.AclOperations.UNKNOWN.Set
inline void          UNKNOWN_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 1.
// func:kafka.AclOperations.ANY.Get
inline bool          ANY_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 1.
// func:kafka.AclOperations.ANY.Set
inline void          ANY_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 2.
// func:kafka.AclOperations.ALL.Get
inline bool          ALL_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 2.
// func:kafka.AclOperations.ALL.Set
inline void          ALL_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 3.
// func:kafka.AclOperations.READ.Get
inline bool          READ_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 3.
// func:kafka.AclOperations.READ.Set
inline void          READ_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 4.
// func:kafka.AclOperations.WRITE.Get
inline bool          WRITE_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 4.
// func:kafka.AclOperations.WRITE.Set
inline void          WRITE_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 5.
// func:kafka.AclOperations.CREATE.Get
inline bool          CREATE_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 5.
// func:kafka.AclOperations.CREATE.Set
inline void          CREATE_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 6.
// func:kafka.AclOperations.DELETE.Get
inline bool          DELETE_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 6.
// func:kafka.AclOperations.DELETE.Set
inline void          DELETE_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 7.
// func:kafka.AclOperations.ALTER.Get
inline bool          ALTER_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 7.
// func:kafka.AclOperations.ALTER.Set
inline void          ALTER_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 8.
// func:kafka.AclOperations.DESCRIBE.Get
inline bool          DESCRIBE_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 8.
// func:kafka.AclOperations.DESCRIBE.Set
inline void          DESCRIBE_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 9.
// func:kafka.AclOperations.CLUSTER_ACTION.Get
inline bool          CLUSTER_ACTION_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 9.
// func:kafka.AclOperations.CLUSTER_ACTION.Set
inline void          CLUSTER_ACTION_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 10.
// func:kafka.AclOperations.DESCRIBE_CONFIGS.Get
inline bool          DESCRIBE_CONFIGS_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 10.
// func:kafka.AclOperations.DESCRIBE_CONFIGS.Set
inline void          DESCRIBE_CONFIGS_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 11.
// func:kafka.AclOperations.ALTER_CONFIGS.Get
inline bool          ALTER_CONFIGS_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 11.
// func:kafka.AclOperations.ALTER_CONFIGS.Set
inline void          ALTER_CONFIGS_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 12.
// func:kafka.AclOperations.IDEMPOTENT_WRITE.Get
inline bool          IDEMPOTENT_WRITE_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 12.
// func:kafka.AclOperations.IDEMPOTENT_WRITE.Set
inline void          IDEMPOTENT_WRITE_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 13.
// func:kafka.AclOperations.CREATE_TOKENS.Get
inline bool          CREATE_TOKENS_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 13.
// func:kafka.AclOperations.CREATE_TOKENS.Set
inline void          CREATE_TOKENS_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 14.
// func:kafka.AclOperations.DESCRIBE_TOKENS.Get
inline bool          DESCRIBE_TOKENS_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 14.
// func:kafka.AclOperations.DESCRIBE_TOKENS.Set
inline void          DESCRIBE_TOKENS_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// Retrieve bitfield from value of field value
//    1 bits starting at bit 31.
// func:kafka.AclOperations.OMITTED.Get
inline bool          OMITTED_Get(const kafka::AclOperations& parent) __attribute__((__warn_unused_result__, nothrow));
// Set bitfield in value of field 'value'
//    1 bits starting at bit 31.
// func:kafka.AclOperations.OMITTED.Set
inline void          OMITTED_Set(kafka::AclOperations& parent, bool rhs) __attribute__((nothrow));

// func:kafka.AclOperations..ReadFieldMaybe
bool                 AclOperations_ReadFieldMaybe(kafka::AclOperations& parent, algo::strptr field, algo::strptr strval) __attribute__((nothrow));
// Read fields of kafka::AclOperations from an ascii string.
// func:kafka.AclOperations..ReadStrptrMaybe
bool                 AclOperations_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.AclOperations..Init
void                 AclOperations_Init(kafka::AclOperations& parent);
// print string representation of ROW to string STR
// cfmt:kafka.AclOperations.String  printfmt:Bitset
// func:kafka.AclOperations..Print
void                 AclOperations_Print(kafka::AclOperations row, algo::cstring& str) __attribute__((nothrow));
// func:kafka.AclOperations..GetAnon
algo::strptr         AclOperations_GetAnon(kafka::AclOperations &parent, i32 idx) __attribute__((nothrow));

// --- kafka.AclPermissionType
#pragma pack(push,1)
struct AclPermissionType { // kafka.AclPermissionType: AclPermission type
    u8   value;   //   0
    // func:kafka.AclPermissionType..Ctor
    inline               AclPermissionType() __attribute__((nothrow));
    // func:kafka.AclPermissionType..FieldwiseCtor
    explicit inline               AclPermissionType(u8 in_value) __attribute__((nothrow));
    // func:kafka.AclPermissionType..EnumCtor
    inline               AclPermissionType(kafka_AclPermissionTypeEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.AclPermissionType.value.GetEnum
inline kafka_AclPermissionTypeEnum value_GetEnum(const kafka::AclPermissionType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.AclPermissionType.value.SetEnum
inline void          value_SetEnum(kafka::AclPermissionType& parent, kafka_AclPermissionTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.AclPermissionType.value.ToCstr
const char*          value_ToCstr(const kafka::AclPermissionType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.AclPermissionType.value.Print
void                 value_Print(const kafka::AclPermissionType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.AclPermissionType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::AclPermissionType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.AclPermissionType.value.SetStrptr
void                 value_SetStrptr(kafka::AclPermissionType& parent, algo::strptr rhs, kafka_AclPermissionTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.AclPermissionType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::AclPermissionType& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::AclPermissionType from an ascii string.
// The format of the string is the format of the kafka::AclPermissionType's only field
// func:kafka.AclPermissionType..ReadStrptrMaybe
bool                 AclPermissionType_ReadStrptrMaybe(kafka::AclPermissionType &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.AclPermissionType..Init
inline void          AclPermissionType_Init(kafka::AclPermissionType& parent);
// print string representation of ROW to string STR
// cfmt:kafka.AclPermissionType.String  printfmt:Raw
// func:kafka.AclPermissionType..Print
void                 AclPermissionType_Print(kafka::AclPermissionType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.CompressionType
struct CompressionType { // kafka.CompressionType
    u8   value;   //   0
    // func:kafka.CompressionType..Ctor
    inline               CompressionType() __attribute__((nothrow));
    // func:kafka.CompressionType..FieldwiseCtor
    explicit inline               CompressionType(u8 in_value) __attribute__((nothrow));
    // func:kafka.CompressionType..EnumCtor
    inline               CompressionType(kafka_CompressionTypeEnum arg) __attribute__((nothrow));
};

// Get value of field as enum type
// func:kafka.CompressionType.value.GetEnum
inline kafka_CompressionTypeEnum value_GetEnum(const kafka::CompressionType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.CompressionType.value.SetEnum
inline void          value_SetEnum(kafka::CompressionType& parent, kafka_CompressionTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.CompressionType.value.ToCstr
const char*          value_ToCstr(const kafka::CompressionType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.CompressionType.value.Print
void                 value_Print(const kafka::CompressionType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.CompressionType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::CompressionType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.CompressionType.value.SetStrptr
void                 value_SetStrptr(kafka::CompressionType& parent, algo::strptr rhs, kafka_CompressionTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.CompressionType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::CompressionType& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::CompressionType from an ascii string.
// The format of the string is the format of the kafka::CompressionType's only field
// func:kafka.CompressionType..ReadStrptrMaybe
bool                 CompressionType_ReadStrptrMaybe(kafka::CompressionType &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.CompressionType..Init
inline void          CompressionType_Init(kafka::CompressionType& parent);
// print string representation of ROW to string STR
// cfmt:kafka.CompressionType.String  printfmt:Raw
// func:kafka.CompressionType..Print
void                 CompressionType_Print(kafka::CompressionType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.ConfigSource
#pragma pack(push,1)
struct ConfigSource { // kafka.ConfigSource: Config type
    u8   value;   //   0
    // func:kafka.ConfigSource..EqOp
    inline bool          operator ==(const kafka::ConfigSource &rhs) const __attribute__((nothrow));
    // func:kafka.ConfigSource..NeOp
    inline bool          operator !=(const kafka::ConfigSource &rhs) const __attribute__((nothrow));
    // define enum comparison operator to avoid ambiguity
    // func:kafka.ConfigSource..EqEnum
    inline bool          operator ==(kafka_ConfigSourceEnum rhs) const __attribute__((nothrow));
    // func:kafka.ConfigSource..Ctor
    inline               ConfigSource() __attribute__((nothrow));
    // func:kafka.ConfigSource..FieldwiseCtor
    explicit inline               ConfigSource(u8 in_value) __attribute__((nothrow));
    // func:kafka.ConfigSource..EnumCtor
    inline               ConfigSource(kafka_ConfigSourceEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.ConfigSource.value.GetEnum
inline kafka_ConfigSourceEnum value_GetEnum(const kafka::ConfigSource& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.ConfigSource.value.SetEnum
inline void          value_SetEnum(kafka::ConfigSource& parent, kafka_ConfigSourceEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.ConfigSource.value.ToCstr
const char*          value_ToCstr(const kafka::ConfigSource& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.ConfigSource.value.Print
void                 value_Print(const kafka::ConfigSource& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.ConfigSource.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::ConfigSource& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.ConfigSource.value.SetStrptr
void                 value_SetStrptr(kafka::ConfigSource& parent, algo::strptr rhs, kafka_ConfigSourceEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.ConfigSource.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::ConfigSource& parent, algo::strptr rhs) __attribute__((nothrow));

// func:kafka.ConfigSource..Hash
inline u32           ConfigSource_Hash(u32 prev, const kafka::ConfigSource& rhs) __attribute__((nothrow));
// Read fields of kafka::ConfigSource from an ascii string.
// The format of the string is the format of the kafka::ConfigSource's only field
// func:kafka.ConfigSource..ReadStrptrMaybe
bool                 ConfigSource_ReadStrptrMaybe(kafka::ConfigSource &parent, algo::strptr in_str) __attribute__((nothrow));
// func:kafka.ConfigSource..Cmp
inline i32           ConfigSource_Cmp(kafka::ConfigSource& lhs, kafka::ConfigSource& rhs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.ConfigSource..Init
inline void          ConfigSource_Init(kafka::ConfigSource& parent);
// func:kafka.ConfigSource..Eq
inline bool          ConfigSource_Eq(kafka::ConfigSource& lhs, kafka::ConfigSource& rhs) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.ConfigSource.String  printfmt:Raw
// func:kafka.ConfigSource..Print
void                 ConfigSource_Print(kafka::ConfigSource& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.ConfigType
#pragma pack(push,1)
struct ConfigType { // kafka.ConfigType: Config type
    u8   value;   //   0
    // func:kafka.ConfigType..EqOp
    inline bool          operator ==(const kafka::ConfigType &rhs) const __attribute__((nothrow));
    // func:kafka.ConfigType..NeOp
    inline bool          operator !=(const kafka::ConfigType &rhs) const __attribute__((nothrow));
    // define enum comparison operator to avoid ambiguity
    // func:kafka.ConfigType..EqEnum
    inline bool          operator ==(kafka_ConfigTypeEnum rhs) const __attribute__((nothrow));
    // func:kafka.ConfigType..Ctor
    inline               ConfigType() __attribute__((nothrow));
    // func:kafka.ConfigType..FieldwiseCtor
    explicit inline               ConfigType(u8 in_value) __attribute__((nothrow));
    // func:kafka.ConfigType..EnumCtor
    inline               ConfigType(kafka_ConfigTypeEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.ConfigType.value.GetEnum
inline kafka_ConfigTypeEnum value_GetEnum(const kafka::ConfigType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.ConfigType.value.SetEnum
inline void          value_SetEnum(kafka::ConfigType& parent, kafka_ConfigTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.ConfigType.value.ToCstr
const char*          value_ToCstr(const kafka::ConfigType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.ConfigType.value.Print
void                 value_Print(const kafka::ConfigType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.ConfigType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::ConfigType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.ConfigType.value.SetStrptr
void                 value_SetStrptr(kafka::ConfigType& parent, algo::strptr rhs, kafka_ConfigTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.ConfigType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::ConfigType& parent, algo::strptr rhs) __attribute__((nothrow));

// func:kafka.ConfigType..Hash
inline u32           ConfigType_Hash(u32 prev, const kafka::ConfigType& rhs) __attribute__((nothrow));
// Read fields of kafka::ConfigType from an ascii string.
// The format of the string is the format of the kafka::ConfigType's only field
// func:kafka.ConfigType..ReadStrptrMaybe
bool                 ConfigType_ReadStrptrMaybe(kafka::ConfigType &parent, algo::strptr in_str) __attribute__((nothrow));
// func:kafka.ConfigType..Cmp
inline i32           ConfigType_Cmp(kafka::ConfigType& lhs, kafka::ConfigType& rhs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.ConfigType..Init
inline void          ConfigType_Init(kafka::ConfigType& parent);
// func:kafka.ConfigType..Eq
inline bool          ConfigType_Eq(kafka::ConfigType& lhs, kafka::ConfigType& rhs) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.ConfigType.String  printfmt:Raw
// func:kafka.ConfigType..Print
void                 ConfigType_Print(kafka::ConfigType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.Error
struct Error { // kafka.Error
    i16   value;   //   0
    // func:kafka.Error.value.Cast
    inline               operator i16() const __attribute__((nothrow));
    // func:kafka.Error..Ctor
    inline               Error() __attribute__((nothrow));
    // func:kafka.Error..FieldwiseCtor
    explicit inline               Error(i16 in_value) __attribute__((nothrow));
};

// Read fields of kafka::Error from an ascii string.
// The format of the string is the format of the kafka::Error's only field
// func:kafka.Error..ReadStrptrMaybe
bool                 Error_ReadStrptrMaybe(kafka::Error &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.Error..Init
inline void          Error_Init(kafka::Error& parent);
// print string representation of ROW to string STR
// cfmt:kafka.Error.String  printfmt:Raw
// func:kafka.Error..Print
void                 Error_Print(kafka::Error& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.FieldId
#pragma pack(push,1)
struct FieldId { // kafka.FieldId: Field read helper
    i32   value;   //   -1
    // func:kafka.FieldId.value.Cast
    inline               operator kafka_FieldIdEnum() const __attribute__((nothrow));
    // func:kafka.FieldId..Ctor
    inline               FieldId() __attribute__((nothrow));
    // func:kafka.FieldId..FieldwiseCtor
    explicit inline               FieldId(i32 in_value) __attribute__((nothrow));
    // func:kafka.FieldId..EnumCtor
    inline               FieldId(kafka_FieldIdEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.FieldId.value.GetEnum
inline kafka_FieldIdEnum value_GetEnum(const kafka::FieldId& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.FieldId.value.SetEnum
inline void          value_SetEnum(kafka::FieldId& parent, kafka_FieldIdEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.FieldId.value.ToCstr
const char*          value_ToCstr(const kafka::FieldId& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.FieldId.value.Print
void                 value_Print(const kafka::FieldId& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.FieldId.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::FieldId& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.FieldId.value.SetStrptr
void                 value_SetStrptr(kafka::FieldId& parent, algo::strptr rhs, kafka_FieldIdEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.FieldId.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::FieldId& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::FieldId from an ascii string.
// The format of the string is the format of the kafka::FieldId's only field
// func:kafka.FieldId..ReadStrptrMaybe
bool                 FieldId_ReadStrptrMaybe(kafka::FieldId &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.FieldId..Init
inline void          FieldId_Init(kafka::FieldId& parent);
// print string representation of ROW to string STR
// cfmt:kafka.FieldId.String  printfmt:Raw
// func:kafka.FieldId..Print
void                 FieldId_Print(kafka::FieldId& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.Frame
// access: kafka.Frame_curs.msg (Ptr)
struct Frame { // kafka.Frame: Frame of binary Kafka protocol
    i32   size_be;   //   0
    // var-length field kafka.Frame.payload starts here. access it with payload_Addr
    // func:kafka.Frame..Ctor
    inline               Frame() __attribute__((nothrow));
};

// func:kafka.Frame.size.Get
inline i32           size_Get(const kafka::Frame& parent) __attribute__((__warn_unused_result__, nothrow));
// func:kafka.Frame.size.Set
inline void          size_Set(kafka::Frame& parent, i32 rhs) __attribute__((nothrow));

// Access var-length portion as an aryptr. Length is determined from one of the fields.
// func:kafka.Frame.payload.Getary
algo::aryptr<u8>     payload_Getary(kafka::Frame& parent) __attribute__((nothrow));
// func:kafka.Frame.payload.Addr
u8*                  payload_Addr(kafka::Frame& parent);
// Return number of elements in varlen field
// func:kafka.Frame.payload.N
inline u32           payload_N(const kafka::Frame& parent) __attribute__((__warn_unused_result__, nothrow, pure));
// Convert payload to a string.
// Array is printed as a regular string.
// func:kafka.Frame.payload.Print
void                 payload_Print(kafka::Frame& parent, algo::cstring &rhs) __attribute__((nothrow));

// func:kafka.Frame.payload_curs.Reset
inline void          Frame_payload_curs_Reset(Frame_payload_curs &curs, kafka::Frame &parent) __attribute__((nothrow));
// cursor points to valid item
// func:kafka.Frame.payload_curs.ValidQ
inline bool          Frame_payload_curs_ValidQ(Frame_payload_curs &curs) __attribute__((nothrow));
// proceed to next item
// func:kafka.Frame.payload_curs.Next
inline void          Frame_payload_curs_Next(Frame_payload_curs &curs) __attribute__((nothrow));
// item access
// func:kafka.Frame.payload_curs.Access
inline u8&           Frame_payload_curs_Access(Frame_payload_curs &curs) __attribute__((nothrow));
// Message length (uses length field)
// func:kafka.Frame..GetMsgLength
inline i32           GetMsgLength(const kafka::Frame& parent) __attribute__((nothrow));
// Memptr encompassing the message (uses length field)
// func:kafka.Frame..GetMsgMemptr
inline algo::memptr  GetMsgMemptr(const kafka::Frame& row) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.Frame..Init
inline void          Frame_Init(kafka::Frame& parent);

// --- kafka.Frame_curs
#pragma pack(push,1)
struct Frame_curs { // kafka.Frame_curs: Cursor for scanning messages in a memptr
    typedef kafka::Frame *ChildType;
    kafka::Frame*   msg;      // Pointer to current message. optional pointer
    u8*             bytes;    // Beginning of region. optional pointer
    i32             limit;    //   0  # Of bytes in the region
    i32             msglen;   //   0  Length of current message (if any)
    // func:kafka.Frame_curs..Ctor
    inline               Frame_curs() __attribute__((nothrow));
};
#pragma pack(pop)

// func:kafka.Frame_curs..ValidQ
inline bool          Frame_curs_ValidQ(kafka::Frame_curs& curs) __attribute__((nothrow));
// func:kafka.Frame_curs..Reset
inline void          Frame_curs_Reset(kafka::Frame_curs& curs, algo::memptr buf) __attribute__((nothrow));
// func:kafka.Frame_curs..Access
inline kafka::Frame*& Frame_curs_Access(kafka::Frame_curs& curs) __attribute__((nothrow));
// func:kafka.Frame_curs..Next
inline void          Frame_curs_Next(kafka::Frame_curs& curs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.Frame_curs..Init
inline void          Frame_curs_Init(kafka::Frame_curs& parent);

// --- kafka.GroupRecordKeyHeader
// access: kafka.OffsetCommitKey.base (Base)
struct GroupRecordKeyHeader { // kafka.GroupRecordKeyHeader
    i16   type;      //   0
    i16   version;   //   0
    // func:kafka.GroupRecordKeyHeader..Ctor
    inline               GroupRecordKeyHeader() __attribute__((nothrow));
};

// Get value of field as enum type
// func:kafka.GroupRecordKeyHeader.type.GetEnum
inline kafka_GroupRecordKeyHeader_type_Enum type_GetEnum(const kafka::GroupRecordKeyHeader& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.GroupRecordKeyHeader.type.SetEnum
inline void          type_SetEnum(kafka::GroupRecordKeyHeader& parent, kafka_GroupRecordKeyHeader_type_Enum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.GroupRecordKeyHeader.type.ToCstr
const char*          type_ToCstr(const kafka::GroupRecordKeyHeader& parent) __attribute__((nothrow));
// Convert type to a string. First, attempt conversion to a known string.
// If no string matches, print type as a numeric value.
// func:kafka.GroupRecordKeyHeader.type.Print
void                 type_Print(const kafka::GroupRecordKeyHeader& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.GroupRecordKeyHeader.type.SetStrptrMaybe
bool                 type_SetStrptrMaybe(kafka::GroupRecordKeyHeader& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.GroupRecordKeyHeader.type.SetStrptr
void                 type_SetStrptr(kafka::GroupRecordKeyHeader& parent, algo::strptr rhs, kafka_GroupRecordKeyHeader_type_Enum dflt) __attribute__((nothrow));

// Set all fields to initial values.
// func:kafka.GroupRecordKeyHeader..Init
inline void          GroupRecordKeyHeader_Init(kafka::GroupRecordKeyHeader& parent);

// --- kafka.GroupRecordKeyHeaderMsgsCase
#pragma pack(push,1)
struct GroupRecordKeyHeaderMsgsCase { // kafka.GroupRecordKeyHeaderMsgsCase: Enum for dispatch kafka.GroupRecordKeyHeaderMsgs
    u32   value;   //   0
    // func:kafka.GroupRecordKeyHeaderMsgsCase.value.Cast
    inline               operator kafka_GroupRecordKeyHeaderMsgsCaseEnum() const __attribute__((nothrow));
    // func:kafka.GroupRecordKeyHeaderMsgsCase..Ctor
    inline               GroupRecordKeyHeaderMsgsCase() __attribute__((nothrow));
    // func:kafka.GroupRecordKeyHeaderMsgsCase..FieldwiseCtor
    explicit inline               GroupRecordKeyHeaderMsgsCase(u32 in_value) __attribute__((nothrow));
    // func:kafka.GroupRecordKeyHeaderMsgsCase..EnumCtor
    inline               GroupRecordKeyHeaderMsgsCase(kafka_GroupRecordKeyHeaderMsgsCaseEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.GetEnum
inline kafka_GroupRecordKeyHeaderMsgsCaseEnum value_GetEnum(const kafka::GroupRecordKeyHeaderMsgsCase& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.SetEnum
inline void          value_SetEnum(kafka::GroupRecordKeyHeaderMsgsCase& parent, kafka_GroupRecordKeyHeaderMsgsCaseEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.ToCstr
const char*          value_ToCstr(const kafka::GroupRecordKeyHeaderMsgsCase& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.Print
void                 value_Print(const kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.SetStrptr
void                 value_SetStrptr(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs, kafka_GroupRecordKeyHeaderMsgsCaseEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.GroupRecordKeyHeaderMsgsCase.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::GroupRecordKeyHeaderMsgsCase from an ascii string.
// The format of the string is the format of the kafka::GroupRecordKeyHeaderMsgsCase's only field
// func:kafka.GroupRecordKeyHeaderMsgsCase..ReadStrptrMaybe
bool                 GroupRecordKeyHeaderMsgsCase_ReadStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.GroupRecordKeyHeaderMsgsCase..Init
inline void          GroupRecordKeyHeaderMsgsCase_Init(kafka::GroupRecordKeyHeaderMsgsCase& parent);

// --- kafka.GroupRecordValueHeader
// access: kafka.OffsetCommitValue.base (Base)
struct GroupRecordValueHeader { // kafka.GroupRecordValueHeader
    i16   type;      //   0
    i16   version;   //   0
    // func:kafka.GroupRecordValueHeader..Ctor
    inline               GroupRecordValueHeader() __attribute__((nothrow));
};

// Get value of field as enum type
// func:kafka.GroupRecordValueHeader.type.GetEnum
inline kafka_GroupRecordValueHeader_type_Enum type_GetEnum(const kafka::GroupRecordValueHeader& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.GroupRecordValueHeader.type.SetEnum
inline void          type_SetEnum(kafka::GroupRecordValueHeader& parent, kafka_GroupRecordValueHeader_type_Enum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.GroupRecordValueHeader.type.ToCstr
const char*          type_ToCstr(const kafka::GroupRecordValueHeader& parent) __attribute__((nothrow));
// Convert type to a string. First, attempt conversion to a known string.
// If no string matches, print type as a numeric value.
// func:kafka.GroupRecordValueHeader.type.Print
void                 type_Print(const kafka::GroupRecordValueHeader& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.GroupRecordValueHeader.type.SetStrptrMaybe
bool                 type_SetStrptrMaybe(kafka::GroupRecordValueHeader& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.GroupRecordValueHeader.type.SetStrptr
void                 type_SetStrptr(kafka::GroupRecordValueHeader& parent, algo::strptr rhs, kafka_GroupRecordValueHeader_type_Enum dflt) __attribute__((nothrow));

// Set all fields to initial values.
// func:kafka.GroupRecordValueHeader..Init
inline void          GroupRecordValueHeader_Init(kafka::GroupRecordValueHeader& parent);

// --- kafka.GroupRecordValueHeaderMsgsCase
#pragma pack(push,1)
struct GroupRecordValueHeaderMsgsCase { // kafka.GroupRecordValueHeaderMsgsCase: Enum for dispatch kafka.GroupRecordValueHeaderMsgs
    u32   value;   //   0
    // func:kafka.GroupRecordValueHeaderMsgsCase.value.Cast
    inline               operator kafka_GroupRecordValueHeaderMsgsCaseEnum() const __attribute__((nothrow));
    // func:kafka.GroupRecordValueHeaderMsgsCase..Ctor
    inline               GroupRecordValueHeaderMsgsCase() __attribute__((nothrow));
    // func:kafka.GroupRecordValueHeaderMsgsCase..FieldwiseCtor
    explicit inline               GroupRecordValueHeaderMsgsCase(u32 in_value) __attribute__((nothrow));
    // func:kafka.GroupRecordValueHeaderMsgsCase..EnumCtor
    inline               GroupRecordValueHeaderMsgsCase(kafka_GroupRecordValueHeaderMsgsCaseEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.GroupRecordValueHeaderMsgsCase.value.GetEnum
inline kafka_GroupRecordValueHeaderMsgsCaseEnum value_GetEnum(const kafka::GroupRecordValueHeaderMsgsCase& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.GroupRecordValueHeaderMsgsCase.value.SetEnum
inline void          value_SetEnum(kafka::GroupRecordValueHeaderMsgsCase& parent, kafka_GroupRecordValueHeaderMsgsCaseEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.GroupRecordValueHeaderMsgsCase.value.ToCstr
const char*          value_ToCstr(const kafka::GroupRecordValueHeaderMsgsCase& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.GroupRecordValueHeaderMsgsCase.value.Print
void                 value_Print(const kafka::GroupRecordValueHeaderMsgsCase& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.GroupRecordValueHeaderMsgsCase.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.GroupRecordValueHeaderMsgsCase.value.SetStrptr
void                 value_SetStrptr(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs, kafka_GroupRecordValueHeaderMsgsCaseEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.GroupRecordValueHeaderMsgsCase.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::GroupRecordValueHeaderMsgsCase from an ascii string.
// The format of the string is the format of the kafka::GroupRecordValueHeaderMsgsCase's only field
// func:kafka.GroupRecordValueHeaderMsgsCase..ReadStrptrMaybe
bool                 GroupRecordValueHeaderMsgsCase_ReadStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.GroupRecordValueHeaderMsgsCase..Init
inline void          GroupRecordValueHeaderMsgsCase_Init(kafka::GroupRecordValueHeaderMsgsCase& parent);

// --- kafka.GroupState
#pragma pack(push,1)
struct GroupState { // kafka.GroupState: Group state
    u8   value;   //   5
    // func:kafka.GroupState..EqOp
    inline bool          operator ==(const kafka::GroupState &rhs) const __attribute__((nothrow));
    // func:kafka.GroupState..NeOp
    inline bool          operator !=(const kafka::GroupState &rhs) const __attribute__((nothrow));
    // define enum comparison operator to avoid ambiguity
    // func:kafka.GroupState..EqEnum
    inline bool          operator ==(kafka_GroupStateEnum rhs) const __attribute__((nothrow));
    // func:kafka.GroupState..Ctor
    inline               GroupState() __attribute__((nothrow));
    // func:kafka.GroupState..FieldwiseCtor
    explicit inline               GroupState(u8 in_value) __attribute__((nothrow));
    // func:kafka.GroupState..EnumCtor
    inline               GroupState(kafka_GroupStateEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.GroupState.value.GetEnum
inline kafka_GroupStateEnum value_GetEnum(const kafka::GroupState& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.GroupState.value.SetEnum
inline void          value_SetEnum(kafka::GroupState& parent, kafka_GroupStateEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.GroupState.value.ToCstr
const char*          value_ToCstr(const kafka::GroupState& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.GroupState.value.Print
void                 value_Print(const kafka::GroupState& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.GroupState.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::GroupState& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.GroupState.value.SetStrptr
void                 value_SetStrptr(kafka::GroupState& parent, algo::strptr rhs, kafka_GroupStateEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.GroupState.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::GroupState& parent, algo::strptr rhs) __attribute__((nothrow));

// func:kafka.GroupState..Hash
inline u32           GroupState_Hash(u32 prev, const kafka::GroupState& rhs) __attribute__((nothrow));
// Read fields of kafka::GroupState from an ascii string.
// The format of the string is the format of the kafka::GroupState's only field
// func:kafka.GroupState..ReadStrptrMaybe
bool                 GroupState_ReadStrptrMaybe(kafka::GroupState &parent, algo::strptr in_str) __attribute__((nothrow));
// func:kafka.GroupState..Cmp
inline i32           GroupState_Cmp(kafka::GroupState& lhs, kafka::GroupState& rhs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.GroupState..Init
inline void          GroupState_Init(kafka::GroupState& parent);
// func:kafka.GroupState..Eq
inline bool          GroupState_Eq(kafka::GroupState& lhs, kafka::GroupState& rhs) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.GroupState.String  printfmt:Raw
// func:kafka.GroupState..Print
void                 GroupState_Print(kafka::GroupState& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.Header
// create: kafka.Record.headers (Tary)
struct Header { // kafka.Header
    algo::cstring   key;     //
    algo::cstring   value;   //
    // func:kafka.Header..Ctor
    inline               Header() __attribute__((nothrow));
};

// func:kafka.Header..ReadFieldMaybe
bool                 Header_ReadFieldMaybe(kafka::Header& parent, algo::strptr field, algo::strptr strval) __attribute__((nothrow));
// Read fields of kafka::Header from an ascii string.
// The format of the string is an ssim Tuple
// func:kafka.Header..ReadStrptrMaybe
bool                 Header_ReadStrptrMaybe(kafka::Header &parent, algo::strptr in_str) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.Header.String  printfmt:Tuple
// func:kafka.Header..Print
void                 Header_Print(kafka::Header& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.OffsetCommitKey
struct OffsetCommitKey { // kafka.OffsetCommitKey
    i16             type;        //   1
    i16             version;     //   0
    algo::cstring   group;       //
    algo::cstring   topic;       //
    i32             partition;   //   0
    // func:kafka.OffsetCommitKey..Ctor
    inline               OffsetCommitKey() __attribute__((nothrow));
};

// Copy fields out of row
// func:kafka.OffsetCommitKey.base.CopyOut
void                 parent_CopyOut(kafka::OffsetCommitKey &row, kafka::GroupRecordKeyHeader &out) __attribute__((nothrow));
// Check if kafka::GroupRecordKeyHeader is an instance of OffsetCommitKey by checking the type field
// If it is, return the pointer of target type.
// If not successful, quietly return NULL.
// func:kafka.OffsetCommitKey.base.Castdown
inline kafka::OffsetCommitKey* OffsetCommitKey_Castdown(kafka::GroupRecordKeyHeader &hdr);
// func:kafka.OffsetCommitKey.base.Castbase
inline kafka::GroupRecordKeyHeader& Castbase(kafka::OffsetCommitKey& parent);

// func:kafka.OffsetCommitKey..ReadFieldMaybe
bool                 OffsetCommitKey_ReadFieldMaybe(kafka::OffsetCommitKey& parent, algo::strptr field, algo::strptr strval) __attribute__((nothrow));
// Read fields of kafka::OffsetCommitKey from an ascii string.
// The format of the string is an ssim Tuple
// func:kafka.OffsetCommitKey..ReadStrptrMaybe
bool                 OffsetCommitKey_ReadStrptrMaybe(kafka::OffsetCommitKey &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.OffsetCommitKey..Init
inline void          OffsetCommitKey_Init(kafka::OffsetCommitKey& parent);
// print string representation of ROW to string STR
// cfmt:kafka.OffsetCommitKey.String  printfmt:Tuple
// func:kafka.OffsetCommitKey..Print
void                 OffsetCommitKey_Print(kafka::OffsetCommitKey& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.OffsetCommitValue
struct OffsetCommitValue { // kafka.OffsetCommitValue
    i16             type;               //   1
    i16             version;            //   0
    i64             offset;             //   0
    i32             leader_epoch;       //   -1
    algo::cstring   metadata;           //
    i64             commit_timestamp;   //   0
    i64             expire_timestamp;   //   -1
    // func:kafka.OffsetCommitValue..Ctor
    inline               OffsetCommitValue() __attribute__((nothrow));
};

// Copy fields out of row
// func:kafka.OffsetCommitValue.base.CopyOut
void                 parent_CopyOut(kafka::OffsetCommitValue &row, kafka::GroupRecordValueHeader &out) __attribute__((nothrow));
// Check if kafka::GroupRecordValueHeader is an instance of OffsetCommitValue by checking the type field
// If it is, return the pointer of target type.
// If not successful, quietly return NULL.
// func:kafka.OffsetCommitValue.base.Castdown
inline kafka::OffsetCommitValue* OffsetCommitValue_Castdown(kafka::GroupRecordValueHeader &hdr);
// func:kafka.OffsetCommitValue.base.Castbase
inline kafka::GroupRecordValueHeader& Castbase(kafka::OffsetCommitValue& parent);

// Set all fields to initial values.
// func:kafka.OffsetCommitValue..Init
inline void          OffsetCommitValue_Init(kafka::OffsetCommitValue& parent);
// print string representation of ROW to string STR
// cfmt:kafka.OffsetCommitValue.String  printfmt:Tuple
// func:kafka.OffsetCommitValue..Print
void                 OffsetCommitValue_Print(kafka::OffsetCommitValue& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.PatternType
#pragma pack(push,1)
struct PatternType { // kafka.PatternType: Pattern type
    u8   value;   //   0
    // func:kafka.PatternType..EqOp
    inline bool          operator ==(const kafka::PatternType &rhs) const __attribute__((nothrow));
    // func:kafka.PatternType..NeOp
    inline bool          operator !=(const kafka::PatternType &rhs) const __attribute__((nothrow));
    // define enum comparison operator to avoid ambiguity
    // func:kafka.PatternType..EqEnum
    inline bool          operator ==(kafka_PatternTypeEnum rhs) const __attribute__((nothrow));
    // func:kafka.PatternType..Ctor
    inline               PatternType() __attribute__((nothrow));
    // func:kafka.PatternType..FieldwiseCtor
    explicit inline               PatternType(u8 in_value) __attribute__((nothrow));
    // func:kafka.PatternType..EnumCtor
    inline               PatternType(kafka_PatternTypeEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.PatternType.value.GetEnum
inline kafka_PatternTypeEnum value_GetEnum(const kafka::PatternType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.PatternType.value.SetEnum
inline void          value_SetEnum(kafka::PatternType& parent, kafka_PatternTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.PatternType.value.ToCstr
const char*          value_ToCstr(const kafka::PatternType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.PatternType.value.Print
void                 value_Print(const kafka::PatternType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.PatternType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::PatternType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.PatternType.value.SetStrptr
void                 value_SetStrptr(kafka::PatternType& parent, algo::strptr rhs, kafka_PatternTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.PatternType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::PatternType& parent, algo::strptr rhs) __attribute__((nothrow));

// func:kafka.PatternType..Hash
inline u32           PatternType_Hash(u32 prev, const kafka::PatternType& rhs) __attribute__((nothrow));
// Read fields of kafka::PatternType from an ascii string.
// The format of the string is the format of the kafka::PatternType's only field
// func:kafka.PatternType..ReadStrptrMaybe
bool                 PatternType_ReadStrptrMaybe(kafka::PatternType &parent, algo::strptr in_str) __attribute__((nothrow));
// func:kafka.PatternType..Cmp
inline i32           PatternType_Cmp(kafka::PatternType& lhs, kafka::PatternType& rhs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.PatternType..Init
inline void          PatternType_Init(kafka::PatternType& parent);
// func:kafka.PatternType..Eq
inline bool          PatternType_Eq(kafka::PatternType& lhs, kafka::PatternType& rhs) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.PatternType.String  printfmt:Raw
// func:kafka.PatternType..Print
void                 PatternType_Print(kafka::PatternType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.Record
// create: kafka.RecordBatch.records (Tary)
struct Record { // kafka.Record
    u8               attributes;        //   0
    u8               pmask;             //   0
    i64              timestamp_delta;   //   0
    i32              offset_delta;      //   0
    algo::cstring    key;               //
    algo::cstring    value;             //
    kafka::Header*   headers_elems;     // pointer to elements
    u32              headers_n;         // number of elements in array
    u32              headers_max;       // max. capacity of array before realloc
    // func:kafka.Record..AssignOp
    kafka::Record&       operator =(const kafka::Record &rhs) __attribute__((nothrow));
    // func:kafka.Record..Ctor
    inline               Record() __attribute__((nothrow));
    // func:kafka.Record..Dtor
    inline               ~Record() __attribute__((nothrow));
    // func:kafka.Record..CopyCtor
    Record(const kafka::Record &rhs) __attribute__((nothrow));
};

// Return constant 1
// func:kafka.Record.pmask.N
inline int           pmask_N(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow, pure));
// Access value
// func:kafka.Record.pmask.qFind
inline u8&           pmask_qFind(kafka::Record& parent, int) __attribute__((__warn_unused_result__, nothrow));
// Get max # of bits in the bitset
// Return max. number of bits supported by array
// func:kafka.Record.pmask.NBits
inline int           pmask_Nbits(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow));
// Retrieve value of bit #BIT_IDX in bit set. No bounds checking
// func:kafka.Record.pmask.qGetBit
inline bool          pmask_qGetBit(kafka::Record& parent, u32 bit_idx) __attribute__((__warn_unused_result__, nothrow));
// Retrieve value of bit #BIT_IDX in bit set. If bit index is out of bounds, return 0.
// func:kafka.Record.pmask.GetBit
inline bool          pmask_GetBit(kafka::Record& parent, u32 bit_idx) __attribute__((__warn_unused_result__, nothrow));
// Check if all the bits in the bitset are equal to zero
// func:kafka.Record.pmask.BitsEmptyQ
inline bool          pmask_BitsEmptyQ(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow));
// func:kafka.Record.pmask.Sum1s
inline u64           pmask_Sum1s(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow));
// Clear bit # BIT_IDX in bit set. No bounds checking
// func:kafka.Record.pmask.qClearBit
inline void          pmask_qClearBit(kafka::Record& parent, u32 bit_idx) __attribute__((nothrow));
// Clear bit # BIT_IDX in bit set. If bit index is out of bounds, do nothing
// func:kafka.Record.pmask.ClearBit
inline void          pmask_ClearBit(kafka::Record& parent, u32 bit_idx) __attribute__((nothrow));
// Set bit # BIT_IDX in bit set. No bounds checking
// func:kafka.Record.pmask.qSetBit
inline void          pmask_qSetBit(kafka::Record& parent, u32 bit_idx) __attribute__((nothrow));
// Set bit # BIT_IDX in bit set. If bit index is out of bounds, do nothing.
// func:kafka.Record.pmask.SetBit
inline void          pmask_SetBit(kafka::Record& parent, u32 bit_idx) __attribute__((nothrow));
// Set bit # BIT_IDX in bit set. No bounds checking
// func:kafka.Record.pmask.qSetBitVal
inline void          pmask_qSetBitVal(kafka::Record& parent, u32 bit_idx, bool val) __attribute__((nothrow));
// Or bit # BIT_IDX in bit set. No bounds checking
// func:kafka.Record.pmask.qOrBitVal
inline void          pmask_qOrBitVal(kafka::Record& parent, u32 bit_idx, bool val) __attribute__((nothrow));
// Set all bits of array to zero.
// Note: this does not change what NBits will return.
// func:kafka.Record.pmask.ClearBitsAll
inline void          pmask_ClearBitsAll(kafka::Record& parent) __attribute__((nothrow));
// Zero in PARENT any bits that are set in RHS.
// func:kafka.Record.pmask.ClearBits
inline void          pmask_ClearBits(kafka::Record& parent, kafka::Record &rhs) __attribute__((nothrow));
// Set PARENT to union of two bitsets.
// (This function is not named Set.. to avoid triple entendre).
// func:kafka.Record.pmask.OrBits
inline void          pmask_OrBits(kafka::Record& parent, kafka::Record &rhs) __attribute__((nothrow));
// Return smallest number N such that indexes of all 1 bits are below N
// func:kafka.Record.pmask.Sup
inline i32           pmask_Sup(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow));

// Return true if the field is marked in the presence mask
// func:kafka.Record.key.PresentQ
inline bool          key_PresentQ(kafka::Record& parent) __attribute__((nothrow));
// Set presence bit for this field in the pmask
// func:kafka.Record.key.SetPresent
inline void          key_SetPresent(kafka::Record& parent) __attribute__((nothrow));
// Return field's bit number in the pmask
// func:kafka.Record.key.Present_GetBit
inline int           key_Present_GetBit(kafka::Record& parent) __attribute__((nothrow));
// func:kafka.Record.key.Set
inline void          key_Set(kafka::Record& parent, const algo::strptr& rhs) __attribute__((nothrow));

// Reserve space (this may move memory). Insert N element at the end.
// Return aryptr to newly inserted block.
// If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
// func:kafka.Record.headers.Addary
algo::aryptr<kafka::Header> headers_Addary(kafka::Record& parent, algo::aryptr<kafka::Header> rhs) __attribute__((nothrow));
// Reserve space. Insert element at the end
// The new element is initialized to a default value
// func:kafka.Record.headers.Alloc
kafka::Header&       headers_Alloc(kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow));
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
// func:kafka.Record.headers.AllocAt
kafka::Header&       headers_AllocAt(kafka::Record& parent, int at) __attribute__((__warn_unused_result__, nothrow));
// Reserve space. Insert N elements at the end of the array, return pointer to array
// func:kafka.Record.headers.AllocN
algo::aryptr<kafka::Header> headers_AllocN(kafka::Record& parent, int n_elems) __attribute__((__warn_unused_result__, nothrow));
// Reserve space. Insert N elements at the given position of the array, return pointer to inserted elements
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
// func:kafka.Record.headers.AllocNAt
algo::aryptr<kafka::Header> headers_AllocNAt(kafka::Record& parent, int n_elems, int at) __attribute__((__warn_unused_result__, nothrow));
// Return true if index is empty
// func:kafka.Record.headers.EmptyQ
inline bool          headers_EmptyQ(kafka::Record& parent) __attribute__((nothrow));
// Look up row by row id. Return NULL if out of range
// func:kafka.Record.headers.Find
inline kafka::Header* headers_Find(kafka::Record& parent, u64 t) __attribute__((__warn_unused_result__, nothrow));
// Return array pointer by value
// func:kafka.Record.headers.Getary
inline algo::aryptr<kafka::Header> headers_Getary(const kafka::Record& parent) __attribute__((nothrow));
// Return pointer to last element of array, or NULL if array is empty
// func:kafka.Record.headers.Last
inline kafka::Header* headers_Last(kafka::Record& parent) __attribute__((nothrow, pure));
// Return max. number of items in the array
// func:kafka.Record.headers.Max
inline i32           headers_Max(kafka::Record& parent) __attribute__((nothrow));
// Return number of items in the array
// func:kafka.Record.headers.N
inline i32           headers_N(const kafka::Record& parent) __attribute__((__warn_unused_result__, nothrow, pure));
// Remove item by index. If index outside of range, do nothing.
// func:kafka.Record.headers.Remove
void                 headers_Remove(kafka::Record& parent, u32 i) __attribute__((nothrow));
// func:kafka.Record.headers.RemoveAll
void                 headers_RemoveAll(kafka::Record& parent) __attribute__((nothrow));
// Delete last element of array. Do nothing if array is empty.
// func:kafka.Record.headers.RemoveLast
void                 headers_RemoveLast(kafka::Record& parent) __attribute__((nothrow));
// Make sure N *more* elements will fit in array. Process dies if out of memory
// func:kafka.Record.headers.Reserve
inline void          headers_Reserve(kafka::Record& parent, int n) __attribute__((nothrow));
// Make sure N elements fit in array. Process dies if out of memory
// func:kafka.Record.headers.AbsReserve
void                 headers_AbsReserve(kafka::Record& parent, int n) __attribute__((nothrow));
// Copy contents of RHS to PARENT.
// func:kafka.Record.headers.Setary
void                 headers_Setary(kafka::Record& parent, kafka::Record &rhs) __attribute__((nothrow));
// Copy specified array into headers, discarding previous contents.
// If the RHS argument aliases the array (refers to the same memory), throw exception.
// func:kafka.Record.headers.Setary2
void                 headers_Setary(kafka::Record& parent, const algo::aryptr<kafka::Header> &rhs) __attribute__((nothrow));
// 'quick' Access row by row id. No bounds checking.
// func:kafka.Record.headers.qFind
inline kafka::Header& headers_qFind(kafka::Record& parent, u64 t) __attribute__((nothrow));
// Return reference to last element of array. No bounds checking
// func:kafka.Record.headers.qLast
inline kafka::Header& headers_qLast(kafka::Record& parent) __attribute__((nothrow));
// Return row id of specified element
// func:kafka.Record.headers.rowid_Get
inline u64           headers_rowid_Get(kafka::Record& parent, kafka::Header &elem) __attribute__((nothrow));
// Reserve space. Insert N elements at the end of the array, return pointer to array
// func:kafka.Record.headers.AllocNVal
algo::aryptr<kafka::Header> headers_AllocNVal(kafka::Record& parent, int n_elems, const kafka::Header& val) __attribute__((nothrow));
// A single element is read from input string and appended to the array.
// If the string contains an error, the array is untouched.
// Function returns success value.
// func:kafka.Record.headers.ReadStrptrMaybe
bool                 headers_ReadStrptrMaybe(kafka::Record& parent, algo::strptr in_str) __attribute__((nothrow));
// Insert array at specific position
// Insert N elements at specified index. Index must be in range or a fatal error occurs.Reserve space, and move existing elements to end.If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
// func:kafka.Record.headers.Insary
void                 headers_Insary(kafka::Record& parent, algo::aryptr<kafka::Header> rhs, int at) __attribute__((nothrow));

// proceed to next item
// func:kafka.Record.headers_curs.Next
inline void          Record_headers_curs_Next(Record_headers_curs &curs) __attribute__((nothrow));
// func:kafka.Record.headers_curs.Reset
inline void          Record_headers_curs_Reset(Record_headers_curs &curs, kafka::Record &parent) __attribute__((nothrow));
// cursor points to valid item
// func:kafka.Record.headers_curs.ValidQ
inline bool          Record_headers_curs_ValidQ(Record_headers_curs &curs) __attribute__((nothrow));
// item access
// func:kafka.Record.headers_curs.Access
inline kafka::Header& Record_headers_curs_Access(Record_headers_curs &curs) __attribute__((nothrow));
// func:kafka.Record..ReadFieldMaybe
bool                 Record_ReadFieldMaybe(kafka::Record& parent, algo::strptr field, algo::strptr strval) __attribute__((nothrow));
// Read fields of kafka::Record from an ascii string.
// The format of the string is an ssim Tuple
// func:kafka.Record..ReadStrptrMaybe
bool                 Record_ReadStrptrMaybe(kafka::Record &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.Record..Init
inline void          Record_Init(kafka::Record& parent);
// func:kafka.Record..Uninit
void                 Record_Uninit(kafka::Record& parent) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.Record.String  printfmt:Tuple
// func:kafka.Record..Print
void                 Record_Print(kafka::Record& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.RecordBatch
struct RecordBatch { // kafka.RecordBatch
    i64              base_offset;              //   0
    i32              partition_leader_epoch;   //   0
    i8               magic;                    //   2
    u32              crc;                      //   0
    i16              attributes;               //   0
    i32              last_offset_delta;        //   0
    i64              base_timestamp;           //   0
    i64              max_timestamp;            //   0
    i64              producer_id;              //   -1
    i16              producer_epoch;           //   -1
    i32              base_sequence;            //   -1
    kafka::Record*   records_elems;            // pointer to elements
    u32              records_n;                // number of elements in array
    u32              records_max;              // max. capacity of array before realloc
    // func:kafka.RecordBatch..AssignOp
    kafka::RecordBatch&  operator =(const kafka::RecordBatch &rhs) __attribute__((nothrow));
    // func:kafka.RecordBatch..Ctor
    inline               RecordBatch() __attribute__((nothrow));
    // func:kafka.RecordBatch..Dtor
    inline               ~RecordBatch() __attribute__((nothrow));
    // func:kafka.RecordBatch..CopyCtor
    RecordBatch(const kafka::RecordBatch &rhs) __attribute__((nothrow));
};

// Reserve space (this may move memory). Insert N element at the end.
// Return aryptr to newly inserted block.
// If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
// func:kafka.RecordBatch.records.Addary
algo::aryptr<kafka::Record> records_Addary(kafka::RecordBatch& parent, algo::aryptr<kafka::Record> rhs) __attribute__((nothrow));
// Reserve space. Insert element at the end
// The new element is initialized to a default value
// func:kafka.RecordBatch.records.Alloc
kafka::Record&       records_Alloc(kafka::RecordBatch& parent) __attribute__((__warn_unused_result__, nothrow));
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
// func:kafka.RecordBatch.records.AllocAt
kafka::Record&       records_AllocAt(kafka::RecordBatch& parent, int at) __attribute__((__warn_unused_result__, nothrow));
// Reserve space. Insert N elements at the end of the array, return pointer to array
// func:kafka.RecordBatch.records.AllocN
algo::aryptr<kafka::Record> records_AllocN(kafka::RecordBatch& parent, int n_elems) __attribute__((__warn_unused_result__, nothrow));
// Reserve space. Insert N elements at the given position of the array, return pointer to inserted elements
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
// func:kafka.RecordBatch.records.AllocNAt
algo::aryptr<kafka::Record> records_AllocNAt(kafka::RecordBatch& parent, int n_elems, int at) __attribute__((__warn_unused_result__, nothrow));
// Return true if index is empty
// func:kafka.RecordBatch.records.EmptyQ
inline bool          records_EmptyQ(kafka::RecordBatch& parent) __attribute__((nothrow));
// Look up row by row id. Return NULL if out of range
// func:kafka.RecordBatch.records.Find
inline kafka::Record* records_Find(kafka::RecordBatch& parent, u64 t) __attribute__((__warn_unused_result__, nothrow));
// Return array pointer by value
// func:kafka.RecordBatch.records.Getary
inline algo::aryptr<kafka::Record> records_Getary(const kafka::RecordBatch& parent) __attribute__((nothrow));
// Return pointer to last element of array, or NULL if array is empty
// func:kafka.RecordBatch.records.Last
inline kafka::Record* records_Last(kafka::RecordBatch& parent) __attribute__((nothrow, pure));
// Return max. number of items in the array
// func:kafka.RecordBatch.records.Max
inline i32           records_Max(kafka::RecordBatch& parent) __attribute__((nothrow));
// Return number of items in the array
// func:kafka.RecordBatch.records.N
inline i32           records_N(const kafka::RecordBatch& parent) __attribute__((__warn_unused_result__, nothrow, pure));
// Remove item by index. If index outside of range, do nothing.
// func:kafka.RecordBatch.records.Remove
void                 records_Remove(kafka::RecordBatch& parent, u32 i) __attribute__((nothrow));
// func:kafka.RecordBatch.records.RemoveAll
void                 records_RemoveAll(kafka::RecordBatch& parent) __attribute__((nothrow));
// Delete last element of array. Do nothing if array is empty.
// func:kafka.RecordBatch.records.RemoveLast
void                 records_RemoveLast(kafka::RecordBatch& parent) __attribute__((nothrow));
// Make sure N *more* elements will fit in array. Process dies if out of memory
// func:kafka.RecordBatch.records.Reserve
inline void          records_Reserve(kafka::RecordBatch& parent, int n) __attribute__((nothrow));
// Make sure N elements fit in array. Process dies if out of memory
// func:kafka.RecordBatch.records.AbsReserve
void                 records_AbsReserve(kafka::RecordBatch& parent, int n) __attribute__((nothrow));
// Copy contents of RHS to PARENT.
// func:kafka.RecordBatch.records.Setary
void                 records_Setary(kafka::RecordBatch& parent, kafka::RecordBatch &rhs) __attribute__((nothrow));
// Copy specified array into records, discarding previous contents.
// If the RHS argument aliases the array (refers to the same memory), throw exception.
// func:kafka.RecordBatch.records.Setary2
void                 records_Setary(kafka::RecordBatch& parent, const algo::aryptr<kafka::Record> &rhs) __attribute__((nothrow));
// 'quick' Access row by row id. No bounds checking.
// func:kafka.RecordBatch.records.qFind
inline kafka::Record& records_qFind(kafka::RecordBatch& parent, u64 t) __attribute__((nothrow));
// Return reference to last element of array. No bounds checking
// func:kafka.RecordBatch.records.qLast
inline kafka::Record& records_qLast(kafka::RecordBatch& parent) __attribute__((nothrow));
// Return row id of specified element
// func:kafka.RecordBatch.records.rowid_Get
inline u64           records_rowid_Get(kafka::RecordBatch& parent, kafka::Record &elem) __attribute__((nothrow));
// Reserve space. Insert N elements at the end of the array, return pointer to array
// func:kafka.RecordBatch.records.AllocNVal
algo::aryptr<kafka::Record> records_AllocNVal(kafka::RecordBatch& parent, int n_elems, const kafka::Record& val) __attribute__((nothrow));
// A single element is read from input string and appended to the array.
// If the string contains an error, the array is untouched.
// Function returns success value.
// func:kafka.RecordBatch.records.ReadStrptrMaybe
bool                 records_ReadStrptrMaybe(kafka::RecordBatch& parent, algo::strptr in_str) __attribute__((nothrow));
// Insert array at specific position
// Insert N elements at specified index. Index must be in range or a fatal error occurs.Reserve space, and move existing elements to end.If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
// func:kafka.RecordBatch.records.Insary
void                 records_Insary(kafka::RecordBatch& parent, algo::aryptr<kafka::Record> rhs, int at) __attribute__((nothrow));

// proceed to next item
// func:kafka.RecordBatch.records_curs.Next
inline void          RecordBatch_records_curs_Next(RecordBatch_records_curs &curs) __attribute__((nothrow));
// func:kafka.RecordBatch.records_curs.Reset
inline void          RecordBatch_records_curs_Reset(RecordBatch_records_curs &curs, kafka::RecordBatch &parent) __attribute__((nothrow));
// cursor points to valid item
// func:kafka.RecordBatch.records_curs.ValidQ
inline bool          RecordBatch_records_curs_ValidQ(RecordBatch_records_curs &curs) __attribute__((nothrow));
// item access
// func:kafka.RecordBatch.records_curs.Access
inline kafka::Record& RecordBatch_records_curs_Access(RecordBatch_records_curs &curs) __attribute__((nothrow));
// func:kafka.RecordBatch..ReadFieldMaybe
bool                 RecordBatch_ReadFieldMaybe(kafka::RecordBatch& parent, algo::strptr field, algo::strptr strval) __attribute__((nothrow));
// Read fields of kafka::RecordBatch from an ascii string.
// The format of the string is an ssim Tuple
// func:kafka.RecordBatch..ReadStrptrMaybe
bool                 RecordBatch_ReadStrptrMaybe(kafka::RecordBatch &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.RecordBatch..Init
void                 RecordBatch_Init(kafka::RecordBatch& parent);
// func:kafka.RecordBatch..Uninit
void                 RecordBatch_Uninit(kafka::RecordBatch& parent) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.RecordBatch.String  printfmt:Tuple
// func:kafka.RecordBatch..Print
void                 RecordBatch_Print(kafka::RecordBatch& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.ResourceType
#pragma pack(push,1)
struct ResourceType { // kafka.ResourceType: Resource type
    u8   value;   //   0
    // func:kafka.ResourceType..EqOp
    inline bool          operator ==(const kafka::ResourceType &rhs) const __attribute__((nothrow));
    // func:kafka.ResourceType..NeOp
    inline bool          operator !=(const kafka::ResourceType &rhs) const __attribute__((nothrow));
    // define enum comparison operator to avoid ambiguity
    // func:kafka.ResourceType..EqEnum
    inline bool          operator ==(kafka_ResourceTypeEnum rhs) const __attribute__((nothrow));
    // func:kafka.ResourceType..Ctor
    inline               ResourceType() __attribute__((nothrow));
    // func:kafka.ResourceType..FieldwiseCtor
    explicit inline               ResourceType(u8 in_value) __attribute__((nothrow));
    // func:kafka.ResourceType..EnumCtor
    inline               ResourceType(kafka_ResourceTypeEnum arg) __attribute__((nothrow));
};
#pragma pack(pop)

// Get value of field as enum type
// func:kafka.ResourceType.value.GetEnum
inline kafka_ResourceTypeEnum value_GetEnum(const kafka::ResourceType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.ResourceType.value.SetEnum
inline void          value_SetEnum(kafka::ResourceType& parent, kafka_ResourceTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.ResourceType.value.ToCstr
const char*          value_ToCstr(const kafka::ResourceType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.ResourceType.value.Print
void                 value_Print(const kafka::ResourceType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.ResourceType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::ResourceType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.ResourceType.value.SetStrptr
void                 value_SetStrptr(kafka::ResourceType& parent, algo::strptr rhs, kafka_ResourceTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.ResourceType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::ResourceType& parent, algo::strptr rhs) __attribute__((nothrow));

// func:kafka.ResourceType..Hash
inline u32           ResourceType_Hash(u32 prev, const kafka::ResourceType& rhs) __attribute__((nothrow));
// Read fields of kafka::ResourceType from an ascii string.
// The format of the string is the format of the kafka::ResourceType's only field
// func:kafka.ResourceType..ReadStrptrMaybe
bool                 ResourceType_ReadStrptrMaybe(kafka::ResourceType &parent, algo::strptr in_str) __attribute__((nothrow));
// func:kafka.ResourceType..Cmp
inline i32           ResourceType_Cmp(kafka::ResourceType& lhs, kafka::ResourceType& rhs) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.ResourceType..Init
inline void          ResourceType_Init(kafka::ResourceType& parent);
// func:kafka.ResourceType..Eq
inline bool          ResourceType_Eq(kafka::ResourceType& lhs, kafka::ResourceType& rhs) __attribute__((nothrow));
// print string representation of ROW to string STR
// cfmt:kafka.ResourceType.String  printfmt:Raw
// func:kafka.ResourceType..Print
void                 ResourceType_Print(kafka::ResourceType& row, algo::cstring& str) __attribute__((nothrow));

// --- kafka.TimestampType
struct TimestampType { // kafka.TimestampType
    u8   value;   //   0
    // func:kafka.TimestampType..Ctor
    inline               TimestampType() __attribute__((nothrow));
    // func:kafka.TimestampType..FieldwiseCtor
    explicit inline               TimestampType(u8 in_value) __attribute__((nothrow));
    // func:kafka.TimestampType..EnumCtor
    inline               TimestampType(kafka_TimestampTypeEnum arg) __attribute__((nothrow));
};

// Get value of field as enum type
// func:kafka.TimestampType.value.GetEnum
inline kafka_TimestampTypeEnum value_GetEnum(const kafka::TimestampType& parent) __attribute__((nothrow));
// Set value of field from enum type.
// func:kafka.TimestampType.value.SetEnum
inline void          value_SetEnum(kafka::TimestampType& parent, kafka_TimestampTypeEnum rhs) __attribute__((nothrow));
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
// func:kafka.TimestampType.value.ToCstr
const char*          value_ToCstr(const kafka::TimestampType& parent) __attribute__((nothrow));
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
// func:kafka.TimestampType.value.Print
void                 value_Print(const kafka::TimestampType& parent, algo::cstring &lhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
// func:kafka.TimestampType.value.SetStrptrMaybe
bool                 value_SetStrptrMaybe(kafka::TimestampType& parent, algo::strptr rhs) __attribute__((nothrow));
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
// func:kafka.TimestampType.value.SetStrptr
void                 value_SetStrptr(kafka::TimestampType& parent, algo::strptr rhs, kafka_TimestampTypeEnum dflt) __attribute__((nothrow));
// Convert string to field. Return success value
// func:kafka.TimestampType.value.ReadStrptrMaybe
bool                 value_ReadStrptrMaybe(kafka::TimestampType& parent, algo::strptr rhs) __attribute__((nothrow));

// Read fields of kafka::TimestampType from an ascii string.
// The format of the string is the format of the kafka::TimestampType's only field
// func:kafka.TimestampType..ReadStrptrMaybe
bool                 TimestampType_ReadStrptrMaybe(kafka::TimestampType &parent, algo::strptr in_str) __attribute__((nothrow));
// Set all fields to initial values.
// func:kafka.TimestampType..Init
inline void          TimestampType_Init(kafka::TimestampType& parent);
// print string representation of ROW to string STR
// cfmt:kafka.TimestampType.String  printfmt:Raw
// func:kafka.TimestampType..Print
void                 TimestampType_Print(kafka::TimestampType& row, algo::cstring& str) __attribute__((nothrow));
} // gen:ns_print_struct
namespace kafka { // gen:ns_curstext

struct Frame_payload_curs {// cursor
    typedef u8 ChildType;
    u8 *ptr;
    int length;
    int index;
    Frame_payload_curs() { ptr=NULL; length=0; index=0; }
};


struct Record_headers_curs {// cursor
    typedef kafka::Header ChildType;
    kafka::Header* elems;
    int n_elems;
    int index;
    Record_headers_curs() { elems=NULL; n_elems=0; index=0; }
};


struct RecordBatch_records_curs {// cursor
    typedef kafka::Record ChildType;
    kafka::Record* elems;
    int n_elems;
    int index;
    RecordBatch_records_curs() { elems=NULL; n_elems=0; index=0; }
};

} // gen:ns_curstext
namespace kafka { // gen:ns_func
// func:kafka...StaticCheck
void                 StaticCheck();
// Print message to STR. If message is too short for MSG_LEN, print nothing.
// MSG.LENGTH must have already been validated against msg_len.
// This function will additionally validate that sizeof(Msg) <= msg_len
// func:kafka.GroupRecordKeyHeaderMsgs..Print
bool                 GroupRecordKeyHeaderMsgs_Print(algo::cstring &str, kafka::GroupRecordKeyHeader &msg, u32 msg_len);
// Print message to STR. If message is too short for MSG_LEN, print nothing.
// MSG.LENGTH must have already been validated against msg_len.
// This function will additionally validate that sizeof(Msg) <= msg_len
// func:kafka.GroupRecordValueHeaderMsgs..Print
bool                 GroupRecordValueHeaderMsgs_Print(algo::cstring &str, kafka::GroupRecordValueHeader &msg, u32 msg_len);
// Parse ascii representation of message into binary, appending new data to BUF.
// func:kafka.GroupRecordKeyHeaderMsgs..ReadStrptr
kafka::GroupRecordKeyHeaderMsgsCase GroupRecordKeyHeaderMsgs_ReadStrptr(algo::strptr str, algo::ByteAry &buf);
// Parse ascii representation of message into binary, appending new data to BUF.
// func:kafka.GroupRecordKeyHeaderMsgs..ReadStrptrMaybe
bool                 GroupRecordKeyHeaderMsgs_ReadStrptrMaybe(algo::strptr str, algo::ByteAry &buf);
// Parse ascii representation of message into binary, appending new data to BUF.
// func:kafka.GroupRecordValueHeaderMsgs..ReadStrptr
kafka::GroupRecordValueHeaderMsgsCase GroupRecordValueHeaderMsgs_ReadStrptr(algo::strptr str, algo::ByteAry &buf);
// Parse ascii representation of message into binary, appending new data to BUF.
// func:kafka.GroupRecordValueHeaderMsgs..ReadStrptrMaybe
bool                 GroupRecordValueHeaderMsgs_ReadStrptrMaybe(algo::strptr str, algo::ByteAry &buf);
} // gen:ns_func
// gen:ns_operators
namespace algo {
inline algo::cstring &operator <<(algo::cstring &str, const kafka::AclOperationType &row);// cfmt:kafka.AclOperationType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::AclOperations &row);// cfmt:kafka.AclOperations.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::AclPermissionType &row);// cfmt:kafka.AclPermissionType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::CompressionType &row);// cfmt:kafka.CompressionType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::ConfigSource &row);// cfmt:kafka.ConfigSource.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::ConfigType &row);// cfmt:kafka.ConfigType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::Error &row);// cfmt:kafka.Error.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::FieldId &row);// cfmt:kafka.FieldId.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::GroupState &row);// cfmt:kafka.GroupState.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::Header &row);// cfmt:kafka.Header.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::OffsetCommitKey &row);// cfmt:kafka.OffsetCommitKey.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::OffsetCommitValue &row);// cfmt:kafka.OffsetCommitValue.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::PatternType &row);// cfmt:kafka.PatternType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::Record &row);// cfmt:kafka.Record.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::RecordBatch &row);// cfmt:kafka.RecordBatch.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::ResourceType &row);// cfmt:kafka.ResourceType.String
inline algo::cstring &operator <<(algo::cstring &str, const kafka::TimestampType &row);// cfmt:kafka.TimestampType.String
}
