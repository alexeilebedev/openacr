//
// cpp/gen/kafka_gen.cpp
// Generated by AMC
//
// Copyright (C) 2008-2013 AlgoEngineering LLC
// Copyright (C) 2013-2019 NYSE | Intercontinental Exchange
// Copyright (C) 2020-2023 Astra
// Copyright (C) 2023 AlgoRND
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <https://www.gnu.org/licenses/>.
//


#include "include/algo.h"  // hard-coded include
#include "include/gen/kafka_gen.h"
#include "include/gen/kafka_gen.inl.h"
#include "include/gen/algo_gen.h"
#include "include/gen/algo_gen.inl.h"
//#pragma endinclude
namespace kafka { // gen:ns_print_proto
    // func:kafka.AclOperations.UNKNOWN.ReadStrptrMaybe
    inline static bool   UNKNOWN_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.ANY.ReadStrptrMaybe
    inline static bool   ANY_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.ALL.ReadStrptrMaybe
    inline static bool   ALL_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.READ.ReadStrptrMaybe
    inline static bool   READ_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.WRITE.ReadStrptrMaybe
    inline static bool   WRITE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.CREATE.ReadStrptrMaybe
    inline static bool   CREATE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.DELETE.ReadStrptrMaybe
    inline static bool   DELETE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.ALTER.ReadStrptrMaybe
    inline static bool   ALTER_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.DESCRIBE.ReadStrptrMaybe
    inline static bool   DESCRIBE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.CLUSTER_ACTION.ReadStrptrMaybe
    inline static bool   CLUSTER_ACTION_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.DESCRIBE_CONFIGS.ReadStrptrMaybe
    inline static bool   DESCRIBE_CONFIGS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.ALTER_CONFIGS.ReadStrptrMaybe
    inline static bool   ALTER_CONFIGS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.IDEMPOTENT_WRITE.ReadStrptrMaybe
    inline static bool   IDEMPOTENT_WRITE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.CREATE_TOKENS.ReadStrptrMaybe
    inline static bool   CREATE_TOKENS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.DESCRIBE_TOKENS.ReadStrptrMaybe
    inline static bool   DESCRIBE_TOKENS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.AclOperations.OMITTED.ReadStrptrMaybe
    inline static bool   OMITTED_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka.Record.key.ReadStrptrMaybe
    inline static bool   key_ReadStrptrMaybe(kafka::Record &parent, algo::strptr in_str) __attribute__((nothrow));
    // func:kafka...SizeCheck
    inline static void   SizeCheck();
} // gen:ns_print_proto

// --- kafka.AclOperationType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::AclOperationType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_AclOperationType_UNKNOWN: ret = "UNKNOWN";  break;
        case kafka_AclOperationType_ANY    : ret = "ANY";  break;
        case kafka_AclOperationType_ALL    : ret = "ALL";  break;
        case kafka_AclOperationType_READ   : ret = "READ";  break;
        case kafka_AclOperationType_WRITE  : ret = "WRITE";  break;
        case kafka_AclOperationType_CREATE : ret = "CREATE";  break;
        case kafka_AclOperationType_DELETE : ret = "DELETE";  break;
        case kafka_AclOperationType_ALTER  : ret = "ALTER";  break;
        case kafka_AclOperationType_DESCRIBE: ret = "DESCRIBE";  break;
        case kafka_AclOperationType_CLUSTER_ACTION: ret = "CLUSTER_ACTION";  break;
        case kafka_AclOperationType_DESCRIBE_CONFIGS: ret = "DESCRIBE_CONFIGS";  break;
        case kafka_AclOperationType_ALTER_CONFIGS: ret = "ALTER_CONFIGS";  break;
        case kafka_AclOperationType_IDEMPOTENT_WRITE: ret = "IDEMPOTENT_WRITE";  break;
        case kafka_AclOperationType_CREATE_TOKENS: ret = "CREATE_TOKENS";  break;
        case kafka_AclOperationType_DESCRIBE_TOKENS: ret = "DESCRIBE_TOKENS";  break;
    }
    return ret;
}

// --- kafka.AclOperationType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::AclOperationType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.AclOperationType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::AclOperationType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('A','L','L'): {
                    value_SetEnum(parent,kafka_AclOperationType_ALL); ret = true; break;
                }
                case LE_STR3('A','N','Y'): {
                    value_SetEnum(parent,kafka_AclOperationType_ANY); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('R','E','A','D'): {
                    value_SetEnum(parent,kafka_AclOperationType_READ); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('A','L','T','E','R'): {
                    value_SetEnum(parent,kafka_AclOperationType_ALTER); ret = true; break;
                }
                case LE_STR5('W','R','I','T','E'): {
                    value_SetEnum(parent,kafka_AclOperationType_WRITE); ret = true; break;
                }
            }
            break;
        }
        case 6: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)) {
                case LE_STR6('C','R','E','A','T','E'): {
                    value_SetEnum(parent,kafka_AclOperationType_CREATE); ret = true; break;
                }
                case LE_STR6('D','E','L','E','T','E'): {
                    value_SetEnum(parent,kafka_AclOperationType_DELETE); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_AclOperationType_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
        case 8: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    value_SetEnum(parent,kafka_AclOperationType_DESCRIBE); ret = true; break;
                }
            }
            break;
        }
        case 13: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('A','L','T','E','R','_','C','O'): {
                    if (memcmp(rhs.elems+8,"NFIGS",5)==0) { value_SetEnum(parent,kafka_AclOperationType_ALTER_CONFIGS); ret = true; break; }
                    break;
                }
                case LE_STR8('C','R','E','A','T','E','_','T'): {
                    if (memcmp(rhs.elems+8,"OKENS",5)==0) { value_SetEnum(parent,kafka_AclOperationType_CREATE_TOKENS); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 14: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('C','L','U','S','T','E','R','_'): {
                    if (memcmp(rhs.elems+8,"ACTION",6)==0) { value_SetEnum(parent,kafka_AclOperationType_CLUSTER_ACTION); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 15: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    if (memcmp(rhs.elems+8,"_TOKENS",7)==0) { value_SetEnum(parent,kafka_AclOperationType_DESCRIBE_TOKENS); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 16: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    if (memcmp(rhs.elems+8,"_CONFIGS",8)==0) { value_SetEnum(parent,kafka_AclOperationType_DESCRIBE_CONFIGS); ret = true; break; }
                    break;
                }
                case LE_STR8('I','D','E','M','P','O','T','E'): {
                    if (memcmp(rhs.elems+8,"NT_WRITE",8)==0) { value_SetEnum(parent,kafka_AclOperationType_IDEMPOTENT_WRITE); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.AclOperationType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::AclOperationType& parent, algo::strptr rhs, kafka_AclOperationTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.AclOperationType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::AclOperationType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.AclOperationType..ReadStrptrMaybe
// Read fields of kafka::AclOperationType from an ascii string.
// The format of the string is the format of the kafka::AclOperationType's only field
bool kafka::AclOperationType_ReadStrptrMaybe(kafka::AclOperationType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.AclOperationType..Print
// print string representation of ROW to string STR
// cfmt:kafka.AclOperationType.String  printfmt:Raw
void kafka::AclOperationType_Print(kafka::AclOperationType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.AclOperations.UNKNOWN.ReadStrptrMaybe
inline static bool kafka::UNKNOWN_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool UNKNOWN_tmp;
    retval = bool_ReadStrptrMaybe(UNKNOWN_tmp, in_str);
    if (retval) {
        UNKNOWN_Set(parent, UNKNOWN_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.ANY.ReadStrptrMaybe
inline static bool kafka::ANY_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool ANY_tmp;
    retval = bool_ReadStrptrMaybe(ANY_tmp, in_str);
    if (retval) {
        ANY_Set(parent, ANY_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.ALL.ReadStrptrMaybe
inline static bool kafka::ALL_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool ALL_tmp;
    retval = bool_ReadStrptrMaybe(ALL_tmp, in_str);
    if (retval) {
        ALL_Set(parent, ALL_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.READ.ReadStrptrMaybe
inline static bool kafka::READ_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool READ_tmp;
    retval = bool_ReadStrptrMaybe(READ_tmp, in_str);
    if (retval) {
        READ_Set(parent, READ_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.WRITE.ReadStrptrMaybe
inline static bool kafka::WRITE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool WRITE_tmp;
    retval = bool_ReadStrptrMaybe(WRITE_tmp, in_str);
    if (retval) {
        WRITE_Set(parent, WRITE_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.CREATE.ReadStrptrMaybe
inline static bool kafka::CREATE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool CREATE_tmp;
    retval = bool_ReadStrptrMaybe(CREATE_tmp, in_str);
    if (retval) {
        CREATE_Set(parent, CREATE_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.DELETE.ReadStrptrMaybe
inline static bool kafka::DELETE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool DELETE_tmp;
    retval = bool_ReadStrptrMaybe(DELETE_tmp, in_str);
    if (retval) {
        DELETE_Set(parent, DELETE_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.ALTER.ReadStrptrMaybe
inline static bool kafka::ALTER_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool ALTER_tmp;
    retval = bool_ReadStrptrMaybe(ALTER_tmp, in_str);
    if (retval) {
        ALTER_Set(parent, ALTER_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.DESCRIBE.ReadStrptrMaybe
inline static bool kafka::DESCRIBE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool DESCRIBE_tmp;
    retval = bool_ReadStrptrMaybe(DESCRIBE_tmp, in_str);
    if (retval) {
        DESCRIBE_Set(parent, DESCRIBE_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.CLUSTER_ACTION.ReadStrptrMaybe
inline static bool kafka::CLUSTER_ACTION_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool CLUSTER_ACTION_tmp;
    retval = bool_ReadStrptrMaybe(CLUSTER_ACTION_tmp, in_str);
    if (retval) {
        CLUSTER_ACTION_Set(parent, CLUSTER_ACTION_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.DESCRIBE_CONFIGS.ReadStrptrMaybe
inline static bool kafka::DESCRIBE_CONFIGS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool DESCRIBE_CONFIGS_tmp;
    retval = bool_ReadStrptrMaybe(DESCRIBE_CONFIGS_tmp, in_str);
    if (retval) {
        DESCRIBE_CONFIGS_Set(parent, DESCRIBE_CONFIGS_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.ALTER_CONFIGS.ReadStrptrMaybe
inline static bool kafka::ALTER_CONFIGS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool ALTER_CONFIGS_tmp;
    retval = bool_ReadStrptrMaybe(ALTER_CONFIGS_tmp, in_str);
    if (retval) {
        ALTER_CONFIGS_Set(parent, ALTER_CONFIGS_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.IDEMPOTENT_WRITE.ReadStrptrMaybe
inline static bool kafka::IDEMPOTENT_WRITE_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool IDEMPOTENT_WRITE_tmp;
    retval = bool_ReadStrptrMaybe(IDEMPOTENT_WRITE_tmp, in_str);
    if (retval) {
        IDEMPOTENT_WRITE_Set(parent, IDEMPOTENT_WRITE_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.CREATE_TOKENS.ReadStrptrMaybe
inline static bool kafka::CREATE_TOKENS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool CREATE_TOKENS_tmp;
    retval = bool_ReadStrptrMaybe(CREATE_TOKENS_tmp, in_str);
    if (retval) {
        CREATE_TOKENS_Set(parent, CREATE_TOKENS_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.DESCRIBE_TOKENS.ReadStrptrMaybe
inline static bool kafka::DESCRIBE_TOKENS_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool DESCRIBE_TOKENS_tmp;
    retval = bool_ReadStrptrMaybe(DESCRIBE_TOKENS_tmp, in_str);
    if (retval) {
        DESCRIBE_TOKENS_Set(parent, DESCRIBE_TOKENS_tmp);
    }
    return retval;
}

// --- kafka.AclOperations.OMITTED.ReadStrptrMaybe
inline static bool kafka::OMITTED_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    bool OMITTED_tmp;
    retval = bool_ReadStrptrMaybe(OMITTED_tmp, in_str);
    if (retval) {
        OMITTED_Set(parent, OMITTED_tmp);
    }
    return retval;
}

// --- kafka.AclOperations..ReadFieldMaybe
bool kafka::AclOperations_ReadFieldMaybe(kafka::AclOperations& parent, algo::strptr field, algo::strptr strval) {
    bool retval = true;
    kafka::FieldId field_id;
    (void)value_SetStrptrMaybe(field_id,field);
    switch(field_id) {
        case kafka_FieldId_value: {
            retval = i32_ReadStrptrMaybe(parent.value, strval);
        } break;
        case kafka_FieldId_UNKNOWN: {
            retval = UNKNOWN_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_ANY: {
            retval = ANY_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_ALL: {
            retval = ALL_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_READ: {
            retval = READ_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_WRITE: {
            retval = WRITE_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_CREATE: {
            retval = CREATE_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_DELETE: {
            retval = DELETE_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_ALTER: {
            retval = ALTER_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_DESCRIBE: {
            retval = DESCRIBE_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_CLUSTER_ACTION: {
            retval = CLUSTER_ACTION_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_DESCRIBE_CONFIGS: {
            retval = DESCRIBE_CONFIGS_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_ALTER_CONFIGS: {
            retval = ALTER_CONFIGS_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_IDEMPOTENT_WRITE: {
            retval = IDEMPOTENT_WRITE_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_CREATE_TOKENS: {
            retval = CREATE_TOKENS_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_DESCRIBE_TOKENS: {
            retval = DESCRIBE_TOKENS_ReadStrptrMaybe(parent, strval);
        } break;
        case kafka_FieldId_OMITTED: {
            retval = OMITTED_ReadStrptrMaybe(parent, strval);
        } break;
        default: {
            retval = false;
            algo_lib::AppendErrtext("comment", "unrecognized attr");
        } break;
    }
    if (!retval) {
        algo_lib::AppendErrtext("attr",field);
    }
    return retval;
}

// --- kafka.AclOperations..ReadStrptrMaybe
// Read fields of kafka::AclOperations from an ascii string.
bool kafka::AclOperations_ReadStrptrMaybe(kafka::AclOperations &parent, algo::strptr in_str) {
    bool retval = true;
    // Clear affected bits first)
    UNKNOWN_Set(parent, false);
    ANY_Set(parent, false);
    ALL_Set(parent, false);
    READ_Set(parent, false);
    WRITE_Set(parent, false);
    CREATE_Set(parent, false);
    DELETE_Set(parent, false);
    ALTER_Set(parent, false);
    DESCRIBE_Set(parent, false);
    CLUSTER_ACTION_Set(parent, false);
    DESCRIBE_CONFIGS_Set(parent, false);
    ALTER_CONFIGS_Set(parent, false);
    IDEMPOTENT_WRITE_Set(parent, false);
    CREATE_TOKENS_Set(parent, false);
    DESCRIBE_TOKENS_Set(parent, false);
    OMITTED_Set(parent, false);
    // Read ','-separated list of bools
    while (ch_N(in_str)) {
        strptr field_name;
        algo::NextSep(in_str,',',field_name);
        field_name = algo::Trimmed(field_name);
        if (ch_N(field_name)) {
            kafka::FieldId field_id;
            bool ok = kafka::value_SetStrptrMaybe(field_id,field_name);
            if (ok) {
                switch (field_id) {
                    case kafka_FieldId_UNKNOWN: {
                        UNKNOWN_Set(parent, true);
                    } break;
                    case kafka_FieldId_ANY: {
                        ANY_Set(parent, true);
                    } break;
                    case kafka_FieldId_ALL: {
                        ALL_Set(parent, true);
                    } break;
                    case kafka_FieldId_READ: {
                        READ_Set(parent, true);
                    } break;
                    case kafka_FieldId_WRITE: {
                        WRITE_Set(parent, true);
                    } break;
                    case kafka_FieldId_CREATE: {
                        CREATE_Set(parent, true);
                    } break;
                    case kafka_FieldId_DELETE: {
                        DELETE_Set(parent, true);
                    } break;
                    case kafka_FieldId_ALTER: {
                        ALTER_Set(parent, true);
                    } break;
                    case kafka_FieldId_DESCRIBE: {
                        DESCRIBE_Set(parent, true);
                    } break;
                    case kafka_FieldId_CLUSTER_ACTION: {
                        CLUSTER_ACTION_Set(parent, true);
                    } break;
                    case kafka_FieldId_DESCRIBE_CONFIGS: {
                        DESCRIBE_CONFIGS_Set(parent, true);
                    } break;
                    case kafka_FieldId_ALTER_CONFIGS: {
                        ALTER_CONFIGS_Set(parent, true);
                    } break;
                    case kafka_FieldId_IDEMPOTENT_WRITE: {
                        IDEMPOTENT_WRITE_Set(parent, true);
                    } break;
                    case kafka_FieldId_CREATE_TOKENS: {
                        CREATE_TOKENS_Set(parent, true);
                    } break;
                    case kafka_FieldId_DESCRIBE_TOKENS: {
                        DESCRIBE_TOKENS_Set(parent, true);
                    } break;
                    case kafka_FieldId_OMITTED: {
                        OMITTED_Set(parent, true);
                    } break;
                    default: ok = false; break;
                }
            }
            if (!ok) {
                algo_lib::AppendErrtext("bitfld",field_name);
                retval = false;
            }
        }
    }
    return retval;
}

// --- kafka.AclOperations..Init
// Set all fields to initial values.
void kafka::AclOperations_Init(kafka::AclOperations& parent) {
    parent.value = i32(0);
}

// --- kafka.AclOperations..Print
// print string representation of ROW to string STR
// cfmt:kafka.AclOperations.String  printfmt:Bitset
void kafka::AclOperations_Print(kafka::AclOperations row, algo::cstring& str) {
    algo::ListSep ls(",");
    if (UNKNOWN_Get(row)) {
        str << ls << "UNKNOWN";
    }
    if (ANY_Get(row)) {
        str << ls << "ANY";
    }
    if (ALL_Get(row)) {
        str << ls << "ALL";
    }
    if (READ_Get(row)) {
        str << ls << "READ";
    }
    if (WRITE_Get(row)) {
        str << ls << "WRITE";
    }
    if (CREATE_Get(row)) {
        str << ls << "CREATE";
    }
    if (DELETE_Get(row)) {
        str << ls << "DELETE";
    }
    if (ALTER_Get(row)) {
        str << ls << "ALTER";
    }
    if (DESCRIBE_Get(row)) {
        str << ls << "DESCRIBE";
    }
    if (CLUSTER_ACTION_Get(row)) {
        str << ls << "CLUSTER_ACTION";
    }
    if (DESCRIBE_CONFIGS_Get(row)) {
        str << ls << "DESCRIBE_CONFIGS";
    }
    if (ALTER_CONFIGS_Get(row)) {
        str << ls << "ALTER_CONFIGS";
    }
    if (IDEMPOTENT_WRITE_Get(row)) {
        str << ls << "IDEMPOTENT_WRITE";
    }
    if (CREATE_TOKENS_Get(row)) {
        str << ls << "CREATE_TOKENS";
    }
    if (DESCRIBE_TOKENS_Get(row)) {
        str << ls << "DESCRIBE_TOKENS";
    }
    if (OMITTED_Get(row)) {
        str << ls << "OMITTED";
    }
}

// --- kafka.AclOperations..GetAnon
algo::strptr kafka::AclOperations_GetAnon(kafka::AclOperations &parent, i32 idx) {
    (void)parent;//only to avoid -Wunused-parameter
    switch(idx) {
        case(0): return strptr("value", 5);
        default: return algo::strptr();
    }
}

// --- kafka.AclPermissionType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::AclPermissionType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_AclPermissionType_UNKNOWN: ret = "UNKNOWN";  break;
        case kafka_AclPermissionType_ANY   : ret = "ANY";  break;
        case kafka_AclPermissionType_DENY  : ret = "DENY";  break;
        case kafka_AclPermissionType_ALLOW : ret = "ALLOW";  break;
    }
    return ret;
}

// --- kafka.AclPermissionType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::AclPermissionType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.AclPermissionType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::AclPermissionType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('A','N','Y'): {
                    value_SetEnum(parent,kafka_AclPermissionType_ANY); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('D','E','N','Y'): {
                    value_SetEnum(parent,kafka_AclPermissionType_DENY); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('A','L','L','O','W'): {
                    value_SetEnum(parent,kafka_AclPermissionType_ALLOW); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_AclPermissionType_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.AclPermissionType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::AclPermissionType& parent, algo::strptr rhs, kafka_AclPermissionTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.AclPermissionType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::AclPermissionType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.AclPermissionType..ReadStrptrMaybe
// Read fields of kafka::AclPermissionType from an ascii string.
// The format of the string is the format of the kafka::AclPermissionType's only field
bool kafka::AclPermissionType_ReadStrptrMaybe(kafka::AclPermissionType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.AclPermissionType..Print
// print string representation of ROW to string STR
// cfmt:kafka.AclPermissionType.String  printfmt:Raw
void kafka::AclPermissionType_Print(kafka::AclPermissionType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.CompressionType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::CompressionType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_CompressionType_no_compression: ret = "no_compression";  break;
        case kafka_CompressionType_gzip    : ret = "gzip";  break;
        case kafka_CompressionType_snappy  : ret = "snappy";  break;
        case kafka_CompressionType_lz4     : ret = "lz4";  break;
        case kafka_CompressionType_zstd    : ret = "zstd";  break;
    }
    return ret;
}

// --- kafka.CompressionType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::CompressionType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.CompressionType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::CompressionType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('l','z','4'): {
                    value_SetEnum(parent,kafka_CompressionType_lz4); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('g','z','i','p'): {
                    value_SetEnum(parent,kafka_CompressionType_gzip); ret = true; break;
                }
                case LE_STR4('z','s','t','d'): {
                    value_SetEnum(parent,kafka_CompressionType_zstd); ret = true; break;
                }
            }
            break;
        }
        case 6: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)) {
                case LE_STR6('s','n','a','p','p','y'): {
                    value_SetEnum(parent,kafka_CompressionType_snappy); ret = true; break;
                }
            }
            break;
        }
        case 14: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('n','o','_','c','o','m','p','r'): {
                    if (memcmp(rhs.elems+8,"ession",6)==0) { value_SetEnum(parent,kafka_CompressionType_no_compression); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.CompressionType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::CompressionType& parent, algo::strptr rhs, kafka_CompressionTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.CompressionType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::CompressionType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.CompressionType..ReadStrptrMaybe
// Read fields of kafka::CompressionType from an ascii string.
// The format of the string is the format of the kafka::CompressionType's only field
bool kafka::CompressionType_ReadStrptrMaybe(kafka::CompressionType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.CompressionType..Print
// print string representation of ROW to string STR
// cfmt:kafka.CompressionType.String  printfmt:Raw
void kafka::CompressionType_Print(kafka::CompressionType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.ConfigSource.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::ConfigSource& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_ConfigSource_UNKNOWN    : ret = "UNKNOWN";  break;
        case kafka_ConfigSource_TOPIC_CONFIG: ret = "TOPIC_CONFIG";  break;
        case kafka_ConfigSource_DYNAMIC_BROKER_CONFIG: ret = "DYNAMIC_BROKER_CONFIG";  break;
        case kafka_ConfigSource_DYNAMIC_DEFAULT_BROKER_CONFIG: ret = "DYNAMIC_DEFAULT_BROKER_CONFIG";  break;
        case kafka_ConfigSource_STATIC_BROKER_CONFIG: ret = "STATIC_BROKER_CONFIG";  break;
        case kafka_ConfigSource_DEFAULT_CONFIG: ret = "DEFAULT_CONFIG";  break;
        case kafka_ConfigSource_DYNAMIC_BROKER_LOGGER_CONFIG: ret = "DYNAMIC_BROKER_LOGGER_CONFIG";  break;
        case kafka_ConfigSource_CLIENT_METRICS_CONFIG: ret = "CLIENT_METRICS_CONFIG";  break;
        case kafka_ConfigSource_GROUP_CONFIG: ret = "GROUP_CONFIG";  break;
    }
    return ret;
}

// --- kafka.ConfigSource.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::ConfigSource& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.ConfigSource.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::ConfigSource& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_ConfigSource_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
        case 12: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('G','R','O','U','P','_','C','O'): {
                    if (memcmp(rhs.elems+8,"NFIG",4)==0) { value_SetEnum(parent,kafka_ConfigSource_GROUP_CONFIG); ret = true; break; }
                    break;
                }
                case LE_STR8('T','O','P','I','C','_','C','O'): {
                    if (memcmp(rhs.elems+8,"NFIG",4)==0) { value_SetEnum(parent,kafka_ConfigSource_TOPIC_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 14: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','F','A','U','L','T','_'): {
                    if (memcmp(rhs.elems+8,"CONFIG",6)==0) { value_SetEnum(parent,kafka_ConfigSource_DEFAULT_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 20: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('S','T','A','T','I','C','_','B'): {
                    if (memcmp(rhs.elems+8,"ROKER_CONFIG",12)==0) { value_SetEnum(parent,kafka_ConfigSource_STATIC_BROKER_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 21: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('C','L','I','E','N','T','_','M'): {
                    if (memcmp(rhs.elems+8,"ETRICS_CONFIG",13)==0) { value_SetEnum(parent,kafka_ConfigSource_CLIENT_METRICS_CONFIG); ret = true; break; }
                    break;
                }
                case LE_STR8('D','Y','N','A','M','I','C','_'): {
                    if (memcmp(rhs.elems+8,"BROKER_CONFIG",13)==0) { value_SetEnum(parent,kafka_ConfigSource_DYNAMIC_BROKER_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 28: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','Y','N','A','M','I','C','_'): {
                    if (memcmp(rhs.elems+8,"BROKER_LOGGER_CONFIG",20)==0) { value_SetEnum(parent,kafka_ConfigSource_DYNAMIC_BROKER_LOGGER_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 29: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','Y','N','A','M','I','C','_'): {
                    if (memcmp(rhs.elems+8,"DEFAULT_BROKER_CONFIG",21)==0) { value_SetEnum(parent,kafka_ConfigSource_DYNAMIC_DEFAULT_BROKER_CONFIG); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.ConfigSource.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::ConfigSource& parent, algo::strptr rhs, kafka_ConfigSourceEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.ConfigSource.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::ConfigSource& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.ConfigSource..ReadStrptrMaybe
// Read fields of kafka::ConfigSource from an ascii string.
// The format of the string is the format of the kafka::ConfigSource's only field
bool kafka::ConfigSource_ReadStrptrMaybe(kafka::ConfigSource &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.ConfigSource..Print
// print string representation of ROW to string STR
// cfmt:kafka.ConfigSource.String  printfmt:Raw
void kafka::ConfigSource_Print(kafka::ConfigSource& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.ConfigType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::ConfigType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_ConfigType_UNKNOWN      : ret = "UNKNOWN";  break;
        case kafka_ConfigType_BOOLEAN      : ret = "BOOLEAN";  break;
        case kafka_ConfigType_STRING       : ret = "STRING";  break;
        case kafka_ConfigType_INT          : ret = "INT";  break;
        case kafka_ConfigType_SHORT        : ret = "SHORT";  break;
        case kafka_ConfigType_LONG         : ret = "LONG";  break;
        case kafka_ConfigType_DOUBLE       : ret = "DOUBLE";  break;
        case kafka_ConfigType_LIST         : ret = "LIST";  break;
        case kafka_ConfigType_CLASS        : ret = "CLASS";  break;
        case kafka_ConfigType_PASSWORD     : ret = "PASSWORD";  break;
    }
    return ret;
}

// --- kafka.ConfigType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::ConfigType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.ConfigType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::ConfigType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('I','N','T'): {
                    value_SetEnum(parent,kafka_ConfigType_INT); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('L','I','S','T'): {
                    value_SetEnum(parent,kafka_ConfigType_LIST); ret = true; break;
                }
                case LE_STR4('L','O','N','G'): {
                    value_SetEnum(parent,kafka_ConfigType_LONG); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('C','L','A','S','S'): {
                    value_SetEnum(parent,kafka_ConfigType_CLASS); ret = true; break;
                }
                case LE_STR5('S','H','O','R','T'): {
                    value_SetEnum(parent,kafka_ConfigType_SHORT); ret = true; break;
                }
            }
            break;
        }
        case 6: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)) {
                case LE_STR6('D','O','U','B','L','E'): {
                    value_SetEnum(parent,kafka_ConfigType_DOUBLE); ret = true; break;
                }
                case LE_STR6('S','T','R','I','N','G'): {
                    value_SetEnum(parent,kafka_ConfigType_STRING); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('B','O','O','L','E','A','N'): {
                    value_SetEnum(parent,kafka_ConfigType_BOOLEAN); ret = true; break;
                }
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_ConfigType_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
        case 8: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('P','A','S','S','W','O','R','D'): {
                    value_SetEnum(parent,kafka_ConfigType_PASSWORD); ret = true; break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.ConfigType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::ConfigType& parent, algo::strptr rhs, kafka_ConfigTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.ConfigType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::ConfigType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.ConfigType..ReadStrptrMaybe
// Read fields of kafka::ConfigType from an ascii string.
// The format of the string is the format of the kafka::ConfigType's only field
bool kafka::ConfigType_ReadStrptrMaybe(kafka::ConfigType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.ConfigType..Print
// print string representation of ROW to string STR
// cfmt:kafka.ConfigType.String  printfmt:Raw
void kafka::ConfigType_Print(kafka::ConfigType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.Error..ReadStrptrMaybe
// Read fields of kafka::Error from an ascii string.
// The format of the string is the format of the kafka::Error's only field
bool kafka::Error_ReadStrptrMaybe(kafka::Error &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && i16_ReadStrptrMaybe(parent.value, in_str);
    return retval;
}

// --- kafka.Error..Print
// print string representation of ROW to string STR
// cfmt:kafka.Error.String  printfmt:Raw
void kafka::Error_Print(kafka::Error& row, algo::cstring& str) {
    i16_Print(row.value, str);
}

// --- kafka.FieldId.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::FieldId& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_FieldId_value           : ret = "value";  break;
        case kafka_FieldId_UNKNOWN         : ret = "UNKNOWN";  break;
        case kafka_FieldId_ANY             : ret = "ANY";  break;
        case kafka_FieldId_ALL             : ret = "ALL";  break;
        case kafka_FieldId_READ            : ret = "READ";  break;
        case kafka_FieldId_WRITE           : ret = "WRITE";  break;
        case kafka_FieldId_CREATE          : ret = "CREATE";  break;
        case kafka_FieldId_DELETE          : ret = "DELETE";  break;
        case kafka_FieldId_ALTER           : ret = "ALTER";  break;
        case kafka_FieldId_DESCRIBE        : ret = "DESCRIBE";  break;
        case kafka_FieldId_CLUSTER_ACTION  : ret = "CLUSTER_ACTION";  break;
        case kafka_FieldId_DESCRIBE_CONFIGS: ret = "DESCRIBE_CONFIGS";  break;
        case kafka_FieldId_ALTER_CONFIGS   : ret = "ALTER_CONFIGS";  break;
        case kafka_FieldId_IDEMPOTENT_WRITE: ret = "IDEMPOTENT_WRITE";  break;
        case kafka_FieldId_CREATE_TOKENS   : ret = "CREATE_TOKENS";  break;
        case kafka_FieldId_DESCRIBE_TOKENS : ret = "DESCRIBE_TOKENS";  break;
        case kafka_FieldId_OMITTED         : ret = "OMITTED";  break;
        case kafka_FieldId_key             : ret = "key";  break;
        case kafka_FieldId_base            : ret = "base";  break;
        case kafka_FieldId_type            : ret = "type";  break;
        case kafka_FieldId_version         : ret = "version";  break;
        case kafka_FieldId_group           : ret = "group";  break;
        case kafka_FieldId_topic           : ret = "topic";  break;
        case kafka_FieldId_partition       : ret = "partition";  break;
        case kafka_FieldId_attributes      : ret = "attributes";  break;
        case kafka_FieldId_pmask           : ret = "pmask";  break;
        case kafka_FieldId_timestamp_delta : ret = "timestamp_delta";  break;
        case kafka_FieldId_offset_delta    : ret = "offset_delta";  break;
        case kafka_FieldId_headers         : ret = "headers";  break;
        case kafka_FieldId_base_offset     : ret = "base_offset";  break;
        case kafka_FieldId_partition_leader_epoch: ret = "partition_leader_epoch";  break;
        case kafka_FieldId_magic           : ret = "magic";  break;
        case kafka_FieldId_crc             : ret = "crc";  break;
        case kafka_FieldId_last_offset_delta: ret = "last_offset_delta";  break;
        case kafka_FieldId_base_timestamp  : ret = "base_timestamp";  break;
        case kafka_FieldId_max_timestamp   : ret = "max_timestamp";  break;
        case kafka_FieldId_producer_id     : ret = "producer_id";  break;
        case kafka_FieldId_producer_epoch  : ret = "producer_epoch";  break;
        case kafka_FieldId_base_sequence   : ret = "base_sequence";  break;
        case kafka_FieldId_records         : ret = "records";  break;
    }
    return ret;
}

// --- kafka.FieldId.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::FieldId& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.FieldId.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::FieldId& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('A','L','L'): {
                    value_SetEnum(parent,kafka_FieldId_ALL); ret = true; break;
                }
                case LE_STR3('A','N','Y'): {
                    value_SetEnum(parent,kafka_FieldId_ANY); ret = true; break;
                }
                case LE_STR3('c','r','c'): {
                    value_SetEnum(parent,kafka_FieldId_crc); ret = true; break;
                }
                case LE_STR3('k','e','y'): {
                    value_SetEnum(parent,kafka_FieldId_key); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('R','E','A','D'): {
                    value_SetEnum(parent,kafka_FieldId_READ); ret = true; break;
                }
                case LE_STR4('b','a','s','e'): {
                    value_SetEnum(parent,kafka_FieldId_base); ret = true; break;
                }
                case LE_STR4('t','y','p','e'): {
                    value_SetEnum(parent,kafka_FieldId_type); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('A','L','T','E','R'): {
                    value_SetEnum(parent,kafka_FieldId_ALTER); ret = true; break;
                }
                case LE_STR5('W','R','I','T','E'): {
                    value_SetEnum(parent,kafka_FieldId_WRITE); ret = true; break;
                }
                case LE_STR5('g','r','o','u','p'): {
                    value_SetEnum(parent,kafka_FieldId_group); ret = true; break;
                }
                case LE_STR5('m','a','g','i','c'): {
                    value_SetEnum(parent,kafka_FieldId_magic); ret = true; break;
                }
                case LE_STR5('p','m','a','s','k'): {
                    value_SetEnum(parent,kafka_FieldId_pmask); ret = true; break;
                }
                case LE_STR5('t','o','p','i','c'): {
                    value_SetEnum(parent,kafka_FieldId_topic); ret = true; break;
                }
                case LE_STR5('v','a','l','u','e'): {
                    value_SetEnum(parent,kafka_FieldId_value); ret = true; break;
                }
            }
            break;
        }
        case 6: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)) {
                case LE_STR6('C','R','E','A','T','E'): {
                    value_SetEnum(parent,kafka_FieldId_CREATE); ret = true; break;
                }
                case LE_STR6('D','E','L','E','T','E'): {
                    value_SetEnum(parent,kafka_FieldId_DELETE); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('O','M','I','T','T','E','D'): {
                    value_SetEnum(parent,kafka_FieldId_OMITTED); ret = true; break;
                }
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_FieldId_UNKNOWN); ret = true; break;
                }
                case LE_STR7('h','e','a','d','e','r','s'): {
                    value_SetEnum(parent,kafka_FieldId_headers); ret = true; break;
                }
                case LE_STR7('r','e','c','o','r','d','s'): {
                    value_SetEnum(parent,kafka_FieldId_records); ret = true; break;
                }
                case LE_STR7('v','e','r','s','i','o','n'): {
                    value_SetEnum(parent,kafka_FieldId_version); ret = true; break;
                }
            }
            break;
        }
        case 8: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    value_SetEnum(parent,kafka_FieldId_DESCRIBE); ret = true; break;
                }
            }
            break;
        }
        case 9: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('p','a','r','t','i','t','i','o'): {
                    if (memcmp(rhs.elems+8,"n",1)==0) { value_SetEnum(parent,kafka_FieldId_partition); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 10: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('a','t','t','r','i','b','u','t'): {
                    if (memcmp(rhs.elems+8,"es",2)==0) { value_SetEnum(parent,kafka_FieldId_attributes); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 11: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('b','a','s','e','_','o','f','f'): {
                    if (memcmp(rhs.elems+8,"set",3)==0) { value_SetEnum(parent,kafka_FieldId_base_offset); ret = true; break; }
                    break;
                }
                case LE_STR8('p','r','o','d','u','c','e','r'): {
                    if (memcmp(rhs.elems+8,"_id",3)==0) { value_SetEnum(parent,kafka_FieldId_producer_id); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 12: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('o','f','f','s','e','t','_','d'): {
                    if (memcmp(rhs.elems+8,"elta",4)==0) { value_SetEnum(parent,kafka_FieldId_offset_delta); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 13: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('A','L','T','E','R','_','C','O'): {
                    if (memcmp(rhs.elems+8,"NFIGS",5)==0) { value_SetEnum(parent,kafka_FieldId_ALTER_CONFIGS); ret = true; break; }
                    break;
                }
                case LE_STR8('C','R','E','A','T','E','_','T'): {
                    if (memcmp(rhs.elems+8,"OKENS",5)==0) { value_SetEnum(parent,kafka_FieldId_CREATE_TOKENS); ret = true; break; }
                    break;
                }
                case LE_STR8('b','a','s','e','_','s','e','q'): {
                    if (memcmp(rhs.elems+8,"uence",5)==0) { value_SetEnum(parent,kafka_FieldId_base_sequence); ret = true; break; }
                    break;
                }
                case LE_STR8('m','a','x','_','t','i','m','e'): {
                    if (memcmp(rhs.elems+8,"stamp",5)==0) { value_SetEnum(parent,kafka_FieldId_max_timestamp); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 14: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('C','L','U','S','T','E','R','_'): {
                    if (memcmp(rhs.elems+8,"ACTION",6)==0) { value_SetEnum(parent,kafka_FieldId_CLUSTER_ACTION); ret = true; break; }
                    break;
                }
                case LE_STR8('b','a','s','e','_','t','i','m'): {
                    if (memcmp(rhs.elems+8,"estamp",6)==0) { value_SetEnum(parent,kafka_FieldId_base_timestamp); ret = true; break; }
                    break;
                }
                case LE_STR8('p','r','o','d','u','c','e','r'): {
                    if (memcmp(rhs.elems+8,"_epoch",6)==0) { value_SetEnum(parent,kafka_FieldId_producer_epoch); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 15: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    if (memcmp(rhs.elems+8,"_TOKENS",7)==0) { value_SetEnum(parent,kafka_FieldId_DESCRIBE_TOKENS); ret = true; break; }
                    break;
                }
                case LE_STR8('t','i','m','e','s','t','a','m'): {
                    if (memcmp(rhs.elems+8,"p_delta",7)==0) { value_SetEnum(parent,kafka_FieldId_timestamp_delta); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 16: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','S','C','R','I','B','E'): {
                    if (memcmp(rhs.elems+8,"_CONFIGS",8)==0) { value_SetEnum(parent,kafka_FieldId_DESCRIBE_CONFIGS); ret = true; break; }
                    break;
                }
                case LE_STR8('I','D','E','M','P','O','T','E'): {
                    if (memcmp(rhs.elems+8,"NT_WRITE",8)==0) { value_SetEnum(parent,kafka_FieldId_IDEMPOTENT_WRITE); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 17: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('l','a','s','t','_','o','f','f'): {
                    if (memcmp(rhs.elems+8,"set_delta",9)==0) { value_SetEnum(parent,kafka_FieldId_last_offset_delta); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 22: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('p','a','r','t','i','t','i','o'): {
                    if (memcmp(rhs.elems+8,"n_leader_epoch",14)==0) { value_SetEnum(parent,kafka_FieldId_partition_leader_epoch); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.FieldId.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::FieldId& parent, algo::strptr rhs, kafka_FieldIdEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.FieldId.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::FieldId& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = i32_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.FieldId..ReadStrptrMaybe
// Read fields of kafka::FieldId from an ascii string.
// The format of the string is the format of the kafka::FieldId's only field
bool kafka::FieldId_ReadStrptrMaybe(kafka::FieldId &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.FieldId..Print
// print string representation of ROW to string STR
// cfmt:kafka.FieldId.String  printfmt:Raw
void kafka::FieldId_Print(kafka::FieldId& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.Frame.payload.Getary
// Access var-length portion as an aryptr. Length is determined from one of the fields.
algo::aryptr<u8> kafka::payload_Getary(kafka::Frame& parent) {
    return algo::aryptr<u8>(payload_Addr(parent), payload_N(parent));
}

// --- kafka.Frame.payload.Addr
u8* kafka::payload_Addr(kafka::Frame& parent) {
    return (u8*)((u8*)&parent + sizeof(kafka::Frame)); // address of varlen portion
}

// --- kafka.Frame.payload.Print
// Convert payload to a string.
// Array is printed as a regular string.
void kafka::payload_Print(kafka::Frame& parent, algo::cstring &rhs) {
    rhs << algo::memptr_ToStrptr(payload_Getary(parent));
}

// --- kafka.GroupRecordKeyHeader.type.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::type_ToCstr(const kafka::GroupRecordKeyHeader& parent) {
    const char *ret = NULL;
    switch(type_GetEnum(parent)) {
        case kafka_GroupRecordKeyHeader_type_kafka_OffsetCommitKey: ret = "kafka.OffsetCommitKey";  break;
    }
    return ret;
}

// --- kafka.GroupRecordKeyHeader.type.Print
// Convert type to a string. First, attempt conversion to a known string.
// If no string matches, print type as a numeric value.
void kafka::type_Print(const kafka::GroupRecordKeyHeader& parent, algo::cstring &lhs) {
    const char *strval = type_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.type;
    }
}

// --- kafka.GroupRecordKeyHeader.type.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::type_SetStrptrMaybe(kafka::GroupRecordKeyHeader& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 21: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('k','a','f','k','a','.','O','f'): {
                    if (memcmp(rhs.elems+8,"fsetCommitKey",13)==0) { type_SetEnum(parent,kafka_GroupRecordKeyHeader_type_kafka_OffsetCommitKey); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.GroupRecordKeyHeader.type.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::type_SetStrptr(kafka::GroupRecordKeyHeader& parent, algo::strptr rhs, kafka_GroupRecordKeyHeader_type_Enum dflt) {
    if (!type_SetStrptrMaybe(parent,rhs)) type_SetEnum(parent,dflt);
}

// --- kafka.GroupRecordKeyHeaderMsgsCase.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::GroupRecordKeyHeaderMsgsCase& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_GroupRecordKeyHeaderMsgsCase_kafka_OffsetCommitKey: ret = "kafka.OffsetCommitKey";  break;
    }
    return ret;
}

// --- kafka.GroupRecordKeyHeaderMsgsCase.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.GroupRecordKeyHeaderMsgsCase.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 21: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('k','a','f','k','a','.','O','f'): {
                    if (memcmp(rhs.elems+8,"fsetCommitKey",13)==0) { value_SetEnum(parent,kafka_GroupRecordKeyHeaderMsgsCase_kafka_OffsetCommitKey); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.GroupRecordKeyHeaderMsgsCase.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs, kafka_GroupRecordKeyHeaderMsgsCaseEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.GroupRecordKeyHeaderMsgsCase.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u32_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.GroupRecordKeyHeaderMsgsCase..ReadStrptrMaybe
// Read fields of kafka::GroupRecordKeyHeaderMsgsCase from an ascii string.
// The format of the string is the format of the kafka::GroupRecordKeyHeaderMsgsCase's only field
bool kafka::GroupRecordKeyHeaderMsgsCase_ReadStrptrMaybe(kafka::GroupRecordKeyHeaderMsgsCase &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.GroupRecordValueHeader.type.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::type_ToCstr(const kafka::GroupRecordValueHeader& parent) {
    const char *ret = NULL;
    switch(type_GetEnum(parent)) {
        case kafka_GroupRecordValueHeader_type_kafka_OffsetCommitValue: ret = "kafka.OffsetCommitValue";  break;
    }
    return ret;
}

// --- kafka.GroupRecordValueHeader.type.Print
// Convert type to a string. First, attempt conversion to a known string.
// If no string matches, print type as a numeric value.
void kafka::type_Print(const kafka::GroupRecordValueHeader& parent, algo::cstring &lhs) {
    const char *strval = type_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.type;
    }
}

// --- kafka.GroupRecordValueHeader.type.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::type_SetStrptrMaybe(kafka::GroupRecordValueHeader& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 23: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('k','a','f','k','a','.','O','f'): {
                    if (memcmp(rhs.elems+8,"fsetCommitValue",15)==0) { type_SetEnum(parent,kafka_GroupRecordValueHeader_type_kafka_OffsetCommitValue); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.GroupRecordValueHeader.type.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::type_SetStrptr(kafka::GroupRecordValueHeader& parent, algo::strptr rhs, kafka_GroupRecordValueHeader_type_Enum dflt) {
    if (!type_SetStrptrMaybe(parent,rhs)) type_SetEnum(parent,dflt);
}

// --- kafka.GroupRecordValueHeaderMsgsCase.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::GroupRecordValueHeaderMsgsCase& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_GroupRecordValueHeaderMsgsCase_kafka_OffsetCommitValue: ret = "kafka.OffsetCommitValue";  break;
    }
    return ret;
}

// --- kafka.GroupRecordValueHeaderMsgsCase.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::GroupRecordValueHeaderMsgsCase& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.GroupRecordValueHeaderMsgsCase.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 23: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('k','a','f','k','a','.','O','f'): {
                    if (memcmp(rhs.elems+8,"fsetCommitValue",15)==0) { value_SetEnum(parent,kafka_GroupRecordValueHeaderMsgsCase_kafka_OffsetCommitValue); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.GroupRecordValueHeaderMsgsCase.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs, kafka_GroupRecordValueHeaderMsgsCaseEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.GroupRecordValueHeaderMsgsCase.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u32_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.GroupRecordValueHeaderMsgsCase..ReadStrptrMaybe
// Read fields of kafka::GroupRecordValueHeaderMsgsCase from an ascii string.
// The format of the string is the format of the kafka::GroupRecordValueHeaderMsgsCase's only field
bool kafka::GroupRecordValueHeaderMsgsCase_ReadStrptrMaybe(kafka::GroupRecordValueHeaderMsgsCase &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.GroupState.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::GroupState& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_GroupState_Unknown      : ret = "Unknown";  break;
        case kafka_GroupState_PreparingRebalance: ret = "PreparingRebalance";  break;
        case kafka_GroupState_CompletingRebalance: ret = "CompletingRebalance";  break;
        case kafka_GroupState_Stable       : ret = "Stable";  break;
        case kafka_GroupState_Dead         : ret = "Dead";  break;
        case kafka_GroupState_Empty        : ret = "Empty";  break;
        case kafka_GroupState_Assigning    : ret = "Assigning";  break;
        case kafka_GroupState_Reconciling  : ret = "Reconciling";  break;
        case kafka_GroupState_NotReady     : ret = "NotReady";  break;
    }
    return ret;
}

// --- kafka.GroupState.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::GroupState& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.GroupState.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::GroupState& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('D','e','a','d'): {
                    value_SetEnum(parent,kafka_GroupState_Dead); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('E','m','p','t','y'): {
                    value_SetEnum(parent,kafka_GroupState_Empty); ret = true; break;
                }
            }
            break;
        }
        case 6: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)) {
                case LE_STR6('S','t','a','b','l','e'): {
                    value_SetEnum(parent,kafka_GroupState_Stable); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('U','n','k','n','o','w','n'): {
                    value_SetEnum(parent,kafka_GroupState_Unknown); ret = true; break;
                }
            }
            break;
        }
        case 8: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('N','o','t','R','e','a','d','y'): {
                    value_SetEnum(parent,kafka_GroupState_NotReady); ret = true; break;
                }
            }
            break;
        }
        case 9: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('A','s','s','i','g','n','i','n'): {
                    if (memcmp(rhs.elems+8,"g",1)==0) { value_SetEnum(parent,kafka_GroupState_Assigning); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 11: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('R','e','c','o','n','c','i','l'): {
                    if (memcmp(rhs.elems+8,"ing",3)==0) { value_SetEnum(parent,kafka_GroupState_Reconciling); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 18: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('P','r','e','p','a','r','i','n'): {
                    if (memcmp(rhs.elems+8,"gRebalance",10)==0) { value_SetEnum(parent,kafka_GroupState_PreparingRebalance); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 19: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('C','o','m','p','l','e','t','i'): {
                    if (memcmp(rhs.elems+8,"ngRebalance",11)==0) { value_SetEnum(parent,kafka_GroupState_CompletingRebalance); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.GroupState.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::GroupState& parent, algo::strptr rhs, kafka_GroupStateEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.GroupState.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::GroupState& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.GroupState..ReadStrptrMaybe
// Read fields of kafka::GroupState from an ascii string.
// The format of the string is the format of the kafka::GroupState's only field
bool kafka::GroupState_ReadStrptrMaybe(kafka::GroupState &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.GroupState..Print
// print string representation of ROW to string STR
// cfmt:kafka.GroupState.String  printfmt:Raw
void kafka::GroupState_Print(kafka::GroupState& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.Header..ReadFieldMaybe
bool kafka::Header_ReadFieldMaybe(kafka::Header& parent, algo::strptr field, algo::strptr strval) {
    bool retval = true;
    kafka::FieldId field_id;
    (void)value_SetStrptrMaybe(field_id,field);
    switch(field_id) {
        case kafka_FieldId_key: {
            retval = algo::cstring_ReadStrptrMaybe(parent.key, strval);
        } break;
        case kafka_FieldId_value: {
            retval = algo::cstring_ReadStrptrMaybe(parent.value, strval);
        } break;
        default: {
            retval = false;
            algo_lib::AppendErrtext("comment", "unrecognized attr");
        } break;
    }
    if (!retval) {
        algo_lib::AppendErrtext("attr",field);
    }
    return retval;
}

// --- kafka.Header..ReadStrptrMaybe
// Read fields of kafka::Header from an ascii string.
// The format of the string is an ssim Tuple
bool kafka::Header_ReadStrptrMaybe(kafka::Header &parent, algo::strptr in_str) {
    bool retval = true;
    retval = algo::StripTypeTag(in_str, "kafka.Header");
    ind_beg(algo::Attr_curs, attr, in_str) {
        retval = retval && Header_ReadFieldMaybe(parent, attr.name, attr.value);
    }ind_end;
    return retval;
}

// --- kafka.Header..Print
// print string representation of ROW to string STR
// cfmt:kafka.Header.String  printfmt:Tuple
void kafka::Header_Print(kafka::Header& row, algo::cstring& str) {
    algo::tempstr temp;
    str << "kafka.Header";

    algo::cstring_Print(row.key, temp);
    PrintAttrSpaceReset(str,"key", temp);

    algo::cstring_Print(row.value, temp);
    PrintAttrSpaceReset(str,"value", temp);
}

// --- kafka.OffsetCommitKey.base.CopyOut
// Copy fields out of row
void kafka::parent_CopyOut(kafka::OffsetCommitKey &row, kafka::GroupRecordKeyHeader &out) {
    // type: field value is computed
    out.version = row.version;
}

// --- kafka.OffsetCommitKey..ReadFieldMaybe
bool kafka::OffsetCommitKey_ReadFieldMaybe(kafka::OffsetCommitKey& parent, algo::strptr field, algo::strptr strval) {
    bool retval = true;
    kafka::FieldId field_id;
    (void)value_SetStrptrMaybe(field_id,field);
    switch(field_id) {
        case kafka_FieldId_base: {
            retval = false;
        } break;
        case kafka_FieldId_type: {
            retval = false;
        } break;
        case kafka_FieldId_version: {
            retval = i16_ReadStrptrMaybe(parent.version, strval);
        } break;
        case kafka_FieldId_group: {
            retval = algo::cstring_ReadStrptrMaybe(parent.group, strval);
        } break;
        case kafka_FieldId_topic: {
            retval = algo::cstring_ReadStrptrMaybe(parent.topic, strval);
        } break;
        case kafka_FieldId_partition: {
            retval = i32_ReadStrptrMaybe(parent.partition, strval);
        } break;
        default: {
            retval = false;
            algo_lib::AppendErrtext("comment", "unrecognized attr");
        } break;
    }
    if (!retval) {
        algo_lib::AppendErrtext("attr",field);
    }
    return retval;
}

// --- kafka.OffsetCommitKey..ReadStrptrMaybe
// Read fields of kafka::OffsetCommitKey from an ascii string.
// The format of the string is an ssim Tuple
bool kafka::OffsetCommitKey_ReadStrptrMaybe(kafka::OffsetCommitKey &parent, algo::strptr in_str) {
    bool retval = true;
    retval = algo::StripTypeTag(in_str, "kafka.OffsetCommitKey");
    ind_beg(algo::Attr_curs, attr, in_str) {
        retval = retval && OffsetCommitKey_ReadFieldMaybe(parent, attr.name, attr.value);
    }ind_end;
    return retval;
}

// --- kafka.OffsetCommitKey..Print
// print string representation of ROW to string STR
// cfmt:kafka.OffsetCommitKey.String  printfmt:Tuple
void kafka::OffsetCommitKey_Print(kafka::OffsetCommitKey& row, algo::cstring& str) {
    algo::tempstr temp;
    str << "kafka.OffsetCommitKey";

    i16_Print(row.version, temp);
    PrintAttrSpaceReset(str,"version", temp);

    algo::cstring_Print(row.group, temp);
    PrintAttrSpaceReset(str,"group", temp);

    algo::cstring_Print(row.topic, temp);
    PrintAttrSpaceReset(str,"topic", temp);

    i32_Print(row.partition, temp);
    PrintAttrSpaceReset(str,"partition", temp);
}

// --- kafka.OffsetCommitValue.base.CopyOut
// Copy fields out of row
void kafka::parent_CopyOut(kafka::OffsetCommitValue &row, kafka::GroupRecordValueHeader &out) {
    // type: field value is computed
    out.version = row.version;
}

// --- kafka.OffsetCommitValue..Print
// print string representation of ROW to string STR
// cfmt:kafka.OffsetCommitValue.String  printfmt:Tuple
void kafka::OffsetCommitValue_Print(kafka::OffsetCommitValue& row, algo::cstring& str) {
    algo::tempstr temp;
    str << "kafka.OffsetCommitValue";

    i16_Print(row.version, temp);
    PrintAttrSpaceReset(str,"version", temp);

    i64_Print(row.offset, temp);
    PrintAttrSpaceReset(str,"offset", temp);

    i32_Print(row.leader_epoch, temp);
    PrintAttrSpaceReset(str,"leader_epoch", temp);

    algo::cstring_Print(row.metadata, temp);
    PrintAttrSpaceReset(str,"metadata", temp);

    i64_Print(row.commit_timestamp, temp);
    PrintAttrSpaceReset(str,"commit_timestamp", temp);

    i64_Print(row.expire_timestamp, temp);
    PrintAttrSpaceReset(str,"expire_timestamp", temp);
}

// --- kafka.PatternType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::PatternType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_PatternType_UNKNOWN     : ret = "UNKNOWN";  break;
        case kafka_PatternType_ANY         : ret = "ANY";  break;
        case kafka_PatternType_MATCH       : ret = "MATCH";  break;
        case kafka_PatternType_LITERAL     : ret = "LITERAL";  break;
        case kafka_PatternType_PREFIXED    : ret = "PREFIXED";  break;
    }
    return ret;
}

// --- kafka.PatternType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::PatternType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.PatternType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::PatternType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('A','N','Y'): {
                    value_SetEnum(parent,kafka_PatternType_ANY); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('M','A','T','C','H'): {
                    value_SetEnum(parent,kafka_PatternType_MATCH); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('L','I','T','E','R','A','L'): {
                    value_SetEnum(parent,kafka_PatternType_LITERAL); ret = true; break;
                }
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_PatternType_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
        case 8: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('P','R','E','F','I','X','E','D'): {
                    value_SetEnum(parent,kafka_PatternType_PREFIXED); ret = true; break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.PatternType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::PatternType& parent, algo::strptr rhs, kafka_PatternTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.PatternType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::PatternType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.PatternType..ReadStrptrMaybe
// Read fields of kafka::PatternType from an ascii string.
// The format of the string is the format of the kafka::PatternType's only field
bool kafka::PatternType_ReadStrptrMaybe(kafka::PatternType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.PatternType..Print
// print string representation of ROW to string STR
// cfmt:kafka.PatternType.String  printfmt:Raw
void kafka::PatternType_Print(kafka::PatternType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.Record.key.ReadStrptrMaybe
inline static bool kafka::key_ReadStrptrMaybe(kafka::Record &parent, algo::strptr in_str) {
    bool retval = true;
    algo::cstring key_tmp;
    retval = algo::cstring_ReadStrptrMaybe(key_tmp, in_str);
    if (retval) {
        key_Set(parent, key_tmp);
    }
    return retval;
}

// --- kafka.Record.headers.Addary
// Reserve space (this may move memory). Insert N element at the end.
// Return aryptr to newly inserted block.
// If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
algo::aryptr<kafka::Header> kafka::headers_Addary(kafka::Record& parent, algo::aryptr<kafka::Header> rhs) {
    bool overlaps = rhs.n_elems>0 && rhs.elems >= parent.headers_elems && rhs.elems < parent.headers_elems + parent.headers_max;
    if (UNLIKELY(overlaps)) {
        FatalErrorExit("kafka.tary_alias  field:kafka.Record.headers  comment:'alias error: sub-array is being appended to the whole'");
    }
    int nnew = rhs.n_elems;
    headers_Reserve(parent, nnew); // reserve space
    int at = parent.headers_n;
    for (int i = 0; i < nnew; i++) {
        new (parent.headers_elems + at + i) kafka::Header(rhs[i]);
        parent.headers_n++;
    }
    return algo::aryptr<kafka::Header>(parent.headers_elems + at, nnew);
}

// --- kafka.Record.headers.Alloc
// Reserve space. Insert element at the end
// The new element is initialized to a default value
kafka::Header& kafka::headers_Alloc(kafka::Record& parent) {
    headers_Reserve(parent, 1);
    int n  = parent.headers_n;
    int at = n;
    kafka::Header *elems = parent.headers_elems;
    new (elems + at) kafka::Header(); // construct new element, default initializer
    parent.headers_n = n+1;
    return elems[at];
}

// --- kafka.Record.headers.AllocAt
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
kafka::Header& kafka::headers_AllocAt(kafka::Record& parent, int at) {
    headers_Reserve(parent, 1);
    int n  = parent.headers_n;
    if (UNLIKELY(u64(at) >= u64(n+1))) {
        FatalErrorExit("kafka.bad_alloc_at  field:kafka.Record.headers  comment:'index out of range'");
    }
    kafka::Header *elems = parent.headers_elems;
    memmove(elems + at + 1, elems + at, (n - at) * sizeof(kafka::Header));
    new (elems + at) kafka::Header(); // construct element, default initializer
    parent.headers_n = n+1;
    return elems[at];
}

// --- kafka.Record.headers.AllocN
// Reserve space. Insert N elements at the end of the array, return pointer to array
algo::aryptr<kafka::Header> kafka::headers_AllocN(kafka::Record& parent, int n_elems) {
    headers_Reserve(parent, n_elems);
    int old_n  = parent.headers_n;
    int new_n = old_n + n_elems;
    kafka::Header *elems = parent.headers_elems;
    for (int i = old_n; i < new_n; i++) {
        new (elems + i) kafka::Header(); // construct new element, default initialize
    }
    parent.headers_n = new_n;
    return algo::aryptr<kafka::Header>(elems + old_n, n_elems);
}

// --- kafka.Record.headers.AllocNAt
// Reserve space. Insert N elements at the given position of the array, return pointer to inserted elements
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
algo::aryptr<kafka::Header> kafka::headers_AllocNAt(kafka::Record& parent, int n_elems, int at) {
    headers_Reserve(parent, n_elems);
    int n  = parent.headers_n;
    if (UNLIKELY(u64(at) > u64(n))) {
        FatalErrorExit("kafka.bad_alloc_n_at  field:kafka.Record.headers  comment:'index out of range'");
    }
    kafka::Header *elems = parent.headers_elems;
    memmove(elems + at + n_elems, elems + at, (n - at) * sizeof(kafka::Header));
    for (int i = 0; i < n_elems; i++) {
        new (elems + at + i) kafka::Header(); // construct new element, default initialize
    }
    parent.headers_n = n+n_elems;
    return algo::aryptr<kafka::Header>(elems+at,n_elems);
}

// --- kafka.Record.headers.Remove
// Remove item by index. If index outside of range, do nothing.
void kafka::headers_Remove(kafka::Record& parent, u32 i) {
    u32 lim = parent.headers_n;
    kafka::Header *elems = parent.headers_elems;
    if (i < lim) {
        elems[i].~Header(); // destroy element
        memmove(elems + i, elems + (i + 1), sizeof(kafka::Header) * (lim - (i + 1)));
        parent.headers_n = lim - 1;
    }
}

// --- kafka.Record.headers.RemoveAll
void kafka::headers_RemoveAll(kafka::Record& parent) {
    u32 n = parent.headers_n;
    while (n > 0) {
        n -= 1;
        parent.headers_elems[n].~Header();
        parent.headers_n = n;
    }
}

// --- kafka.Record.headers.RemoveLast
// Delete last element of array. Do nothing if array is empty.
void kafka::headers_RemoveLast(kafka::Record& parent) {
    u64 n = parent.headers_n;
    if (n > 0) {
        n -= 1;
        headers_qFind(parent, u64(n)).~Header();
        parent.headers_n = n;
    }
}

// --- kafka.Record.headers.AbsReserve
// Make sure N elements fit in array. Process dies if out of memory
void kafka::headers_AbsReserve(kafka::Record& parent, int n) {
    u32 old_max  = parent.headers_max;
    if (n > i32(old_max)) {
        u32 new_max  = i32_Max(i32_Max(old_max * 2, n), 4);
        void *new_mem = algo_lib::malloc_ReallocMem(parent.headers_elems, old_max * sizeof(kafka::Header), new_max * sizeof(kafka::Header));
        if (UNLIKELY(!new_mem)) {
            FatalErrorExit("kafka.tary_nomem  field:kafka.Record.headers  comment:'out of memory'");
        }
        parent.headers_elems = (kafka::Header*)new_mem;
        parent.headers_max = new_max;
    }
}

// --- kafka.Record.headers.Setary
// Copy contents of RHS to PARENT.
void kafka::headers_Setary(kafka::Record& parent, kafka::Record &rhs) {
    headers_RemoveAll(parent);
    int nnew = rhs.headers_n;
    headers_Reserve(parent, nnew); // reserve space
    for (int i = 0; i < nnew; i++) { // copy elements over
        new (parent.headers_elems + i) kafka::Header(headers_qFind(rhs, i));
        parent.headers_n = i + 1;
    }
}

// --- kafka.Record.headers.Setary2
// Copy specified array into headers, discarding previous contents.
// If the RHS argument aliases the array (refers to the same memory), throw exception.
void kafka::headers_Setary(kafka::Record& parent, const algo::aryptr<kafka::Header> &rhs) {
    headers_RemoveAll(parent);
    headers_Addary(parent, rhs);
}

// --- kafka.Record.headers.AllocNVal
// Reserve space. Insert N elements at the end of the array, return pointer to array
algo::aryptr<kafka::Header> kafka::headers_AllocNVal(kafka::Record& parent, int n_elems, const kafka::Header& val) {
    headers_Reserve(parent, n_elems);
    int old_n  = parent.headers_n;
    int new_n = old_n + n_elems;
    kafka::Header *elems = parent.headers_elems;
    for (int i = old_n; i < new_n; i++) {
        new (elems + i) kafka::Header(val);
    }
    parent.headers_n = new_n;
    return algo::aryptr<kafka::Header>(elems + old_n, n_elems);
}

// --- kafka.Record.headers.ReadStrptrMaybe
// A single element is read from input string and appended to the array.
// If the string contains an error, the array is untouched.
// Function returns success value.
bool kafka::headers_ReadStrptrMaybe(kafka::Record& parent, algo::strptr in_str) {
    bool retval = true;
    kafka::Header &elem = headers_Alloc(parent);
    retval = kafka::Header_ReadStrptrMaybe(elem, in_str);
    if (!retval) {
        headers_RemoveLast(parent);
    }
    return retval;
}

// --- kafka.Record.headers.Insary
// Insert array at specific position
// Insert N elements at specified index. Index must be in range or a fatal error occurs.Reserve space, and move existing elements to end.If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
void kafka::headers_Insary(kafka::Record& parent, algo::aryptr<kafka::Header> rhs, int at) {
    bool overlaps = rhs.n_elems>0 && rhs.elems >= parent.headers_elems && rhs.elems < parent.headers_elems + parent.headers_max;
    if (UNLIKELY(overlaps)) {
        FatalErrorExit("kafka.tary_alias  field:kafka.Record.headers  comment:'alias error: sub-array is being appended to the whole'");
    }
    if (UNLIKELY(u64(at) >= u64(parent.headers_elems+1))) {
        FatalErrorExit("kafka.bad_insary  field:kafka.Record.headers  comment:'index out of range'");
    }
    int nnew = rhs.n_elems;
    int nmove = parent.headers_n - at;
    headers_Reserve(parent, nnew); // reserve space
    for (int i = nmove-1; i >=0 ; --i) {
        new (parent.headers_elems + at + nnew + i) kafka::Header(parent.headers_elems[at + i]);
        parent.headers_elems[at + i].~Header(); // destroy element
    }
    for (int i = 0; i < nnew; ++i) {
        new (parent.headers_elems + at + i) kafka::Header(rhs[i]);
    }
    parent.headers_n += nnew;
}

// --- kafka.Record..ReadFieldMaybe
bool kafka::Record_ReadFieldMaybe(kafka::Record& parent, algo::strptr field, algo::strptr strval) {
    bool retval = true;
    kafka::FieldId field_id;
    (void)value_SetStrptrMaybe(field_id,algo::Pathcomp(field, ".LL"));
    switch(field_id) {
        case kafka_FieldId_attributes: {
            retval = u8_ReadStrptrMaybe(parent.attributes, strval);
        } break;
        case kafka_FieldId_pmask: {
            retval = false;
        } break;
        case kafka_FieldId_timestamp_delta: {
            retval = i64_ReadStrptrMaybe(parent.timestamp_delta, strval);
        } break;
        case kafka_FieldId_offset_delta: {
            retval = i32_ReadStrptrMaybe(parent.offset_delta, strval);
        } break;
        case kafka_FieldId_key: {
            retval = key_ReadStrptrMaybe(parent, strval);
            if (retval) {
                pmask_qSetBit(parent, 0);
            }
        } break;
        case kafka_FieldId_value: {
            retval = algo::cstring_ReadStrptrMaybe(parent.value, strval);
        } break;
        case kafka_FieldId_headers: {
            retval = headers_ReadStrptrMaybe(parent, strval);
        } break;
        default: {
            retval = false;
            algo_lib::AppendErrtext("comment", "unrecognized attr");
        } break;
    }
    if (!retval) {
        algo_lib::AppendErrtext("attr",field);
    }
    return retval;
}

// --- kafka.Record..ReadStrptrMaybe
// Read fields of kafka::Record from an ascii string.
// The format of the string is an ssim Tuple
bool kafka::Record_ReadStrptrMaybe(kafka::Record &parent, algo::strptr in_str) {
    bool retval = true;
    retval = algo::StripTypeTag(in_str, "kafka.Record");
    ind_beg(algo::Attr_curs, attr, in_str) {
        retval = retval && Record_ReadFieldMaybe(parent, attr.name, attr.value);
    }ind_end;
    return retval;
}

// --- kafka.Record..Uninit
void kafka::Record_Uninit(kafka::Record& parent) {
    kafka::Record &row = parent; (void)row;

    // kafka.Record.headers.Uninit (Tary)  //
    // remove all elements from kafka.Record.headers
    headers_RemoveAll(parent);
    // free memory for Tary kafka.Record.headers
    algo_lib::malloc_FreeMem(parent.headers_elems, sizeof(kafka::Header)*parent.headers_max); // (kafka.Record.headers)
}

// --- kafka.Record..Print
// print string representation of ROW to string STR
// cfmt:kafka.Record.String  printfmt:Tuple
void kafka::Record_Print(kafka::Record& row, algo::cstring& str) {
    algo::tempstr temp;
    str << "kafka.Record";

    u8_Print(row.attributes, temp);
    PrintAttrSpaceReset(str,"attributes", temp);

    i64_Print(row.timestamp_delta, temp);
    PrintAttrSpaceReset(str,"timestamp_delta", temp);

    i32_Print(row.offset_delta, temp);
    PrintAttrSpaceReset(str,"offset_delta", temp);

    if (key_PresentQ(row)) {
        algo::cstring_Print(row.key, temp);
        PrintAttrSpaceReset(str,"key", temp);
    }

    algo::cstring_Print(row.value, temp);
    PrintAttrSpaceReset(str,"value", temp);

    ind_beg(Record_headers_curs,headers,row) {
        kafka::Header_Print(headers, temp);
        tempstr name;
        name << "headers.";
        name << ind_curs(headers).index;
        PrintAttrSpaceReset(str, name, temp);
    }ind_end;
}

// --- kafka.Record..AssignOp
kafka::Record& kafka::Record::operator =(const kafka::Record &rhs) {
    attributes = rhs.attributes;
    pmask = rhs.pmask;
    timestamp_delta = rhs.timestamp_delta;
    offset_delta = rhs.offset_delta;
    key = rhs.key;
    value = rhs.value;
    headers_Setary(*this, headers_Getary(const_cast<kafka::Record&>(rhs)));
    return *this;
}

// --- kafka.Record..CopyCtor
 kafka::Record::Record(const kafka::Record &rhs)
    : attributes(rhs.attributes)
    , pmask(rhs.pmask)
    , timestamp_delta(rhs.timestamp_delta)
    , offset_delta(rhs.offset_delta)
    , key(rhs.key)
    , value(rhs.value)
 {
    headers_elems 	= 0; // (kafka.Record.headers)
    headers_n     	= 0; // (kafka.Record.headers)
    headers_max   	= 0; // (kafka.Record.headers)
    headers_Setary(*this, headers_Getary(const_cast<kafka::Record&>(rhs)));
}

// --- kafka.RecordBatch.records.Addary
// Reserve space (this may move memory). Insert N element at the end.
// Return aryptr to newly inserted block.
// If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
algo::aryptr<kafka::Record> kafka::records_Addary(kafka::RecordBatch& parent, algo::aryptr<kafka::Record> rhs) {
    bool overlaps = rhs.n_elems>0 && rhs.elems >= parent.records_elems && rhs.elems < parent.records_elems + parent.records_max;
    if (UNLIKELY(overlaps)) {
        FatalErrorExit("kafka.tary_alias  field:kafka.RecordBatch.records  comment:'alias error: sub-array is being appended to the whole'");
    }
    int nnew = rhs.n_elems;
    records_Reserve(parent, nnew); // reserve space
    int at = parent.records_n;
    for (int i = 0; i < nnew; i++) {
        new (parent.records_elems + at + i) kafka::Record(rhs[i]);
        parent.records_n++;
    }
    return algo::aryptr<kafka::Record>(parent.records_elems + at, nnew);
}

// --- kafka.RecordBatch.records.Alloc
// Reserve space. Insert element at the end
// The new element is initialized to a default value
kafka::Record& kafka::records_Alloc(kafka::RecordBatch& parent) {
    records_Reserve(parent, 1);
    int n  = parent.records_n;
    int at = n;
    kafka::Record *elems = parent.records_elems;
    new (elems + at) kafka::Record(); // construct new element, default initializer
    parent.records_n = n+1;
    return elems[at];
}

// --- kafka.RecordBatch.records.AllocAt
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
kafka::Record& kafka::records_AllocAt(kafka::RecordBatch& parent, int at) {
    records_Reserve(parent, 1);
    int n  = parent.records_n;
    if (UNLIKELY(u64(at) >= u64(n+1))) {
        FatalErrorExit("kafka.bad_alloc_at  field:kafka.RecordBatch.records  comment:'index out of range'");
    }
    kafka::Record *elems = parent.records_elems;
    memmove(elems + at + 1, elems + at, (n - at) * sizeof(kafka::Record));
    new (elems + at) kafka::Record(); // construct element, default initializer
    parent.records_n = n+1;
    return elems[at];
}

// --- kafka.RecordBatch.records.AllocN
// Reserve space. Insert N elements at the end of the array, return pointer to array
algo::aryptr<kafka::Record> kafka::records_AllocN(kafka::RecordBatch& parent, int n_elems) {
    records_Reserve(parent, n_elems);
    int old_n  = parent.records_n;
    int new_n = old_n + n_elems;
    kafka::Record *elems = parent.records_elems;
    for (int i = old_n; i < new_n; i++) {
        new (elems + i) kafka::Record(); // construct new element, default initialize
    }
    parent.records_n = new_n;
    return algo::aryptr<kafka::Record>(elems + old_n, n_elems);
}

// --- kafka.RecordBatch.records.AllocNAt
// Reserve space. Insert N elements at the given position of the array, return pointer to inserted elements
// Reserve space for new element, reallocating the array if necessary
// Insert new element at specified index. Index must be in range or a fatal error occurs.
algo::aryptr<kafka::Record> kafka::records_AllocNAt(kafka::RecordBatch& parent, int n_elems, int at) {
    records_Reserve(parent, n_elems);
    int n  = parent.records_n;
    if (UNLIKELY(u64(at) > u64(n))) {
        FatalErrorExit("kafka.bad_alloc_n_at  field:kafka.RecordBatch.records  comment:'index out of range'");
    }
    kafka::Record *elems = parent.records_elems;
    memmove(elems + at + n_elems, elems + at, (n - at) * sizeof(kafka::Record));
    for (int i = 0; i < n_elems; i++) {
        new (elems + at + i) kafka::Record(); // construct new element, default initialize
    }
    parent.records_n = n+n_elems;
    return algo::aryptr<kafka::Record>(elems+at,n_elems);
}

// --- kafka.RecordBatch.records.Remove
// Remove item by index. If index outside of range, do nothing.
void kafka::records_Remove(kafka::RecordBatch& parent, u32 i) {
    u32 lim = parent.records_n;
    kafka::Record *elems = parent.records_elems;
    if (i < lim) {
        elems[i].~Record(); // destroy element
        memmove(elems + i, elems + (i + 1), sizeof(kafka::Record) * (lim - (i + 1)));
        parent.records_n = lim - 1;
    }
}

// --- kafka.RecordBatch.records.RemoveAll
void kafka::records_RemoveAll(kafka::RecordBatch& parent) {
    u32 n = parent.records_n;
    while (n > 0) {
        n -= 1;
        parent.records_elems[n].~Record();
        parent.records_n = n;
    }
}

// --- kafka.RecordBatch.records.RemoveLast
// Delete last element of array. Do nothing if array is empty.
void kafka::records_RemoveLast(kafka::RecordBatch& parent) {
    u64 n = parent.records_n;
    if (n > 0) {
        n -= 1;
        records_qFind(parent, u64(n)).~Record();
        parent.records_n = n;
    }
}

// --- kafka.RecordBatch.records.AbsReserve
// Make sure N elements fit in array. Process dies if out of memory
void kafka::records_AbsReserve(kafka::RecordBatch& parent, int n) {
    u32 old_max  = parent.records_max;
    if (n > i32(old_max)) {
        u32 new_max  = i32_Max(i32_Max(old_max * 2, n), 4);
        void *new_mem = algo_lib::malloc_ReallocMem(parent.records_elems, old_max * sizeof(kafka::Record), new_max * sizeof(kafka::Record));
        if (UNLIKELY(!new_mem)) {
            FatalErrorExit("kafka.tary_nomem  field:kafka.RecordBatch.records  comment:'out of memory'");
        }
        parent.records_elems = (kafka::Record*)new_mem;
        parent.records_max = new_max;
    }
}

// --- kafka.RecordBatch.records.Setary
// Copy contents of RHS to PARENT.
void kafka::records_Setary(kafka::RecordBatch& parent, kafka::RecordBatch &rhs) {
    records_RemoveAll(parent);
    int nnew = rhs.records_n;
    records_Reserve(parent, nnew); // reserve space
    for (int i = 0; i < nnew; i++) { // copy elements over
        new (parent.records_elems + i) kafka::Record(records_qFind(rhs, i));
        parent.records_n = i + 1;
    }
}

// --- kafka.RecordBatch.records.Setary2
// Copy specified array into records, discarding previous contents.
// If the RHS argument aliases the array (refers to the same memory), throw exception.
void kafka::records_Setary(kafka::RecordBatch& parent, const algo::aryptr<kafka::Record> &rhs) {
    records_RemoveAll(parent);
    records_Addary(parent, rhs);
}

// --- kafka.RecordBatch.records.AllocNVal
// Reserve space. Insert N elements at the end of the array, return pointer to array
algo::aryptr<kafka::Record> kafka::records_AllocNVal(kafka::RecordBatch& parent, int n_elems, const kafka::Record& val) {
    records_Reserve(parent, n_elems);
    int old_n  = parent.records_n;
    int new_n = old_n + n_elems;
    kafka::Record *elems = parent.records_elems;
    for (int i = old_n; i < new_n; i++) {
        new (elems + i) kafka::Record(val);
    }
    parent.records_n = new_n;
    return algo::aryptr<kafka::Record>(elems + old_n, n_elems);
}

// --- kafka.RecordBatch.records.ReadStrptrMaybe
// A single element is read from input string and appended to the array.
// If the string contains an error, the array is untouched.
// Function returns success value.
bool kafka::records_ReadStrptrMaybe(kafka::RecordBatch& parent, algo::strptr in_str) {
    bool retval = true;
    kafka::Record &elem = records_Alloc(parent);
    retval = kafka::Record_ReadStrptrMaybe(elem, in_str);
    if (!retval) {
        records_RemoveLast(parent);
    }
    return retval;
}

// --- kafka.RecordBatch.records.Insary
// Insert array at specific position
// Insert N elements at specified index. Index must be in range or a fatal error occurs.Reserve space, and move existing elements to end.If the RHS argument aliases the array (refers to the same memory), exit program with fatal error.
void kafka::records_Insary(kafka::RecordBatch& parent, algo::aryptr<kafka::Record> rhs, int at) {
    bool overlaps = rhs.n_elems>0 && rhs.elems >= parent.records_elems && rhs.elems < parent.records_elems + parent.records_max;
    if (UNLIKELY(overlaps)) {
        FatalErrorExit("kafka.tary_alias  field:kafka.RecordBatch.records  comment:'alias error: sub-array is being appended to the whole'");
    }
    if (UNLIKELY(u64(at) >= u64(parent.records_elems+1))) {
        FatalErrorExit("kafka.bad_insary  field:kafka.RecordBatch.records  comment:'index out of range'");
    }
    int nnew = rhs.n_elems;
    int nmove = parent.records_n - at;
    records_Reserve(parent, nnew); // reserve space
    for (int i = nmove-1; i >=0 ; --i) {
        new (parent.records_elems + at + nnew + i) kafka::Record(parent.records_elems[at + i]);
        parent.records_elems[at + i].~Record(); // destroy element
    }
    for (int i = 0; i < nnew; ++i) {
        new (parent.records_elems + at + i) kafka::Record(rhs[i]);
    }
    parent.records_n += nnew;
}

// --- kafka.RecordBatch..ReadFieldMaybe
bool kafka::RecordBatch_ReadFieldMaybe(kafka::RecordBatch& parent, algo::strptr field, algo::strptr strval) {
    bool retval = true;
    kafka::FieldId field_id;
    (void)value_SetStrptrMaybe(field_id,algo::Pathcomp(field, ".LL"));
    switch(field_id) {
        case kafka_FieldId_base_offset: {
            retval = i64_ReadStrptrMaybe(parent.base_offset, strval);
        } break;
        case kafka_FieldId_partition_leader_epoch: {
            retval = i32_ReadStrptrMaybe(parent.partition_leader_epoch, strval);
        } break;
        case kafka_FieldId_magic: {
            retval = i8_ReadStrptrMaybe(parent.magic, strval);
        } break;
        case kafka_FieldId_crc: {
            retval = u32_ReadStrptrMaybe(parent.crc, strval);
        } break;
        case kafka_FieldId_attributes: {
            retval = i16_ReadStrptrMaybe(parent.attributes, strval);
        } break;
        case kafka_FieldId_last_offset_delta: {
            retval = i32_ReadStrptrMaybe(parent.last_offset_delta, strval);
        } break;
        case kafka_FieldId_base_timestamp: {
            retval = i64_ReadStrptrMaybe(parent.base_timestamp, strval);
        } break;
        case kafka_FieldId_max_timestamp: {
            retval = i64_ReadStrptrMaybe(parent.max_timestamp, strval);
        } break;
        case kafka_FieldId_producer_id: {
            retval = i64_ReadStrptrMaybe(parent.producer_id, strval);
        } break;
        case kafka_FieldId_producer_epoch: {
            retval = i16_ReadStrptrMaybe(parent.producer_epoch, strval);
        } break;
        case kafka_FieldId_base_sequence: {
            retval = i32_ReadStrptrMaybe(parent.base_sequence, strval);
        } break;
        case kafka_FieldId_records: {
            retval = records_ReadStrptrMaybe(parent, strval);
        } break;
        default: {
            retval = false;
            algo_lib::AppendErrtext("comment", "unrecognized attr");
        } break;
    }
    if (!retval) {
        algo_lib::AppendErrtext("attr",field);
    }
    return retval;
}

// --- kafka.RecordBatch..ReadStrptrMaybe
// Read fields of kafka::RecordBatch from an ascii string.
// The format of the string is an ssim Tuple
bool kafka::RecordBatch_ReadStrptrMaybe(kafka::RecordBatch &parent, algo::strptr in_str) {
    bool retval = true;
    retval = algo::StripTypeTag(in_str, "kafka.RecordBatch");
    ind_beg(algo::Attr_curs, attr, in_str) {
        retval = retval && RecordBatch_ReadFieldMaybe(parent, attr.name, attr.value);
    }ind_end;
    return retval;
}

// --- kafka.RecordBatch..Init
// Set all fields to initial values.
void kafka::RecordBatch_Init(kafka::RecordBatch& parent) {
    parent.base_offset = i64(0);
    parent.partition_leader_epoch = i32(0);
    parent.magic = i8(2);
    parent.crc = u32(0);
    parent.attributes = i16(0);
    parent.last_offset_delta = i32(0);
    parent.base_timestamp = i64(0);
    parent.max_timestamp = i64(0);
    parent.producer_id = i64(-1);
    parent.producer_epoch = i16(-1);
    parent.base_sequence = i32(-1);
    parent.records_elems 	= 0; // (kafka.RecordBatch.records)
    parent.records_n     	= 0; // (kafka.RecordBatch.records)
    parent.records_max   	= 0; // (kafka.RecordBatch.records)
}

// --- kafka.RecordBatch..Uninit
void kafka::RecordBatch_Uninit(kafka::RecordBatch& parent) {
    kafka::RecordBatch &row = parent; (void)row;

    // kafka.RecordBatch.records.Uninit (Tary)  //
    // remove all elements from kafka.RecordBatch.records
    records_RemoveAll(parent);
    // free memory for Tary kafka.RecordBatch.records
    algo_lib::malloc_FreeMem(parent.records_elems, sizeof(kafka::Record)*parent.records_max); // (kafka.RecordBatch.records)
}

// --- kafka.RecordBatch..Print
// print string representation of ROW to string STR
// cfmt:kafka.RecordBatch.String  printfmt:Tuple
void kafka::RecordBatch_Print(kafka::RecordBatch& row, algo::cstring& str) {
    algo::tempstr temp;
    str << "kafka.RecordBatch";

    i64_Print(row.base_offset, temp);
    PrintAttrSpaceReset(str,"base_offset", temp);

    i32_Print(row.partition_leader_epoch, temp);
    PrintAttrSpaceReset(str,"partition_leader_epoch", temp);

    i8_Print(row.magic, temp);
    PrintAttrSpaceReset(str,"magic", temp);

    u32_Print(row.crc, temp);
    PrintAttrSpaceReset(str,"crc", temp);

    i16_Print(row.attributes, temp);
    PrintAttrSpaceReset(str,"attributes", temp);

    i32_Print(row.last_offset_delta, temp);
    PrintAttrSpaceReset(str,"last_offset_delta", temp);

    i64_Print(row.base_timestamp, temp);
    PrintAttrSpaceReset(str,"base_timestamp", temp);

    i64_Print(row.max_timestamp, temp);
    PrintAttrSpaceReset(str,"max_timestamp", temp);

    i64_Print(row.producer_id, temp);
    PrintAttrSpaceReset(str,"producer_id", temp);

    i16_Print(row.producer_epoch, temp);
    PrintAttrSpaceReset(str,"producer_epoch", temp);

    i32_Print(row.base_sequence, temp);
    PrintAttrSpaceReset(str,"base_sequence", temp);

    ind_beg(RecordBatch_records_curs,records,row) {
        kafka::Record_Print(records, temp);
        tempstr name;
        name << "records.";
        name << ind_curs(records).index;
        PrintAttrSpaceReset(str, name, temp);
    }ind_end;
}

// --- kafka.RecordBatch..AssignOp
kafka::RecordBatch& kafka::RecordBatch::operator =(const kafka::RecordBatch &rhs) {
    base_offset = rhs.base_offset;
    partition_leader_epoch = rhs.partition_leader_epoch;
    magic = rhs.magic;
    crc = rhs.crc;
    attributes = rhs.attributes;
    last_offset_delta = rhs.last_offset_delta;
    base_timestamp = rhs.base_timestamp;
    max_timestamp = rhs.max_timestamp;
    producer_id = rhs.producer_id;
    producer_epoch = rhs.producer_epoch;
    base_sequence = rhs.base_sequence;
    records_Setary(*this, records_Getary(const_cast<kafka::RecordBatch&>(rhs)));
    return *this;
}

// --- kafka.RecordBatch..CopyCtor
 kafka::RecordBatch::RecordBatch(const kafka::RecordBatch &rhs)
    : base_offset(rhs.base_offset)
    , partition_leader_epoch(rhs.partition_leader_epoch)
    , magic(rhs.magic)
    , crc(rhs.crc)
    , attributes(rhs.attributes)
    , last_offset_delta(rhs.last_offset_delta)
    , base_timestamp(rhs.base_timestamp)
    , max_timestamp(rhs.max_timestamp)
    , producer_id(rhs.producer_id)
    , producer_epoch(rhs.producer_epoch)
    , base_sequence(rhs.base_sequence)
 {
    records_elems 	= 0; // (kafka.RecordBatch.records)
    records_n     	= 0; // (kafka.RecordBatch.records)
    records_max   	= 0; // (kafka.RecordBatch.records)
    records_Setary(*this, records_Getary(const_cast<kafka::RecordBatch&>(rhs)));
}

// --- kafka.ResourceType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::ResourceType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_ResourceType_UNKNOWN    : ret = "UNKNOWN";  break;
        case kafka_ResourceType_ANY        : ret = "ANY";  break;
        case kafka_ResourceType_TOPIC      : ret = "TOPIC";  break;
        case kafka_ResourceType_GROUP      : ret = "GROUP";  break;
        case kafka_ResourceType_CLUSTER    : ret = "CLUSTER";  break;
        case kafka_ResourceType_TRANSACTIONAL_ID: ret = "TRANSACTIONAL_ID";  break;
        case kafka_ResourceType_DELEGATION_TOKEN: ret = "DELEGATION_TOKEN";  break;
        case kafka_ResourceType_USER       : ret = "USER";  break;
    }
    return ret;
}

// --- kafka.ResourceType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::ResourceType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.ResourceType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::ResourceType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 3: {
            switch (u64(algo::ReadLE16(rhs.elems))|(u64(rhs[2])<<16)) {
                case LE_STR3('A','N','Y'): {
                    value_SetEnum(parent,kafka_ResourceType_ANY); ret = true; break;
                }
            }
            break;
        }
        case 4: {
            switch (u64(algo::ReadLE32(rhs.elems))) {
                case LE_STR4('U','S','E','R'): {
                    value_SetEnum(parent,kafka_ResourceType_USER); ret = true; break;
                }
            }
            break;
        }
        case 5: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(rhs[4])<<32)) {
                case LE_STR5('G','R','O','U','P'): {
                    value_SetEnum(parent,kafka_ResourceType_GROUP); ret = true; break;
                }
                case LE_STR5('T','O','P','I','C'): {
                    value_SetEnum(parent,kafka_ResourceType_TOPIC); ret = true; break;
                }
            }
            break;
        }
        case 7: {
            switch (u64(algo::ReadLE32(rhs.elems))|(u64(algo::ReadLE16(rhs.elems+4))<<32)|(u64(rhs[6])<<48)) {
                case LE_STR7('C','L','U','S','T','E','R'): {
                    value_SetEnum(parent,kafka_ResourceType_CLUSTER); ret = true; break;
                }
                case LE_STR7('U','N','K','N','O','W','N'): {
                    value_SetEnum(parent,kafka_ResourceType_UNKNOWN); ret = true; break;
                }
            }
            break;
        }
        case 16: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('D','E','L','E','G','A','T','I'): {
                    if (memcmp(rhs.elems+8,"ON_TOKEN",8)==0) { value_SetEnum(parent,kafka_ResourceType_DELEGATION_TOKEN); ret = true; break; }
                    break;
                }
                case LE_STR8('T','R','A','N','S','A','C','T'): {
                    if (memcmp(rhs.elems+8,"IONAL_ID",8)==0) { value_SetEnum(parent,kafka_ResourceType_TRANSACTIONAL_ID); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.ResourceType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::ResourceType& parent, algo::strptr rhs, kafka_ResourceTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.ResourceType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::ResourceType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.ResourceType..ReadStrptrMaybe
// Read fields of kafka::ResourceType from an ascii string.
// The format of the string is the format of the kafka::ResourceType's only field
bool kafka::ResourceType_ReadStrptrMaybe(kafka::ResourceType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.ResourceType..Print
// print string representation of ROW to string STR
// cfmt:kafka.ResourceType.String  printfmt:Raw
void kafka::ResourceType_Print(kafka::ResourceType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka.TimestampType.value.ToCstr
// Convert numeric value of field to one of predefined string constants.
// If string is found, return a static C string. Otherwise, return NULL.
const char* kafka::value_ToCstr(const kafka::TimestampType& parent) {
    const char *ret = NULL;
    switch(value_GetEnum(parent)) {
        case kafka_TimestampType_create_time: ret = "create_time";  break;
        case kafka_TimestampType_log_append_time: ret = "log_append_time";  break;
    }
    return ret;
}

// --- kafka.TimestampType.value.Print
// Convert value to a string. First, attempt conversion to a known string.
// If no string matches, print value as a numeric value.
void kafka::value_Print(const kafka::TimestampType& parent, algo::cstring &lhs) {
    const char *strval = value_ToCstr(parent);
    if (strval) {
        lhs << strval;
    } else {
        lhs << parent.value;
    }
}

// --- kafka.TimestampType.value.SetStrptrMaybe
// Convert string to field.
// If the string is invalid, do not modify field and return false.
// In case of success, return true
bool kafka::value_SetStrptrMaybe(kafka::TimestampType& parent, algo::strptr rhs) {
    bool ret = false;
    switch (elems_N(rhs)) {
        case 11: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('c','r','e','a','t','e','_','t'): {
                    if (memcmp(rhs.elems+8,"ime",3)==0) { value_SetEnum(parent,kafka_TimestampType_create_time); ret = true; break; }
                    break;
                }
            }
            break;
        }
        case 15: {
            switch (algo::ReadLE64(rhs.elems)) {
                case LE_STR8('l','o','g','_','a','p','p','e'): {
                    if (memcmp(rhs.elems+8,"nd_time",7)==0) { value_SetEnum(parent,kafka_TimestampType_log_append_time); ret = true; break; }
                    break;
                }
            }
            break;
        }
    }
    return ret;
}

// --- kafka.TimestampType.value.SetStrptr
// Convert string to field.
// If the string is invalid, set numeric value to DFLT
void kafka::value_SetStrptr(kafka::TimestampType& parent, algo::strptr rhs, kafka_TimestampTypeEnum dflt) {
    if (!value_SetStrptrMaybe(parent,rhs)) value_SetEnum(parent,dflt);
}

// --- kafka.TimestampType.value.ReadStrptrMaybe
// Convert string to field. Return success value
bool kafka::value_ReadStrptrMaybe(kafka::TimestampType& parent, algo::strptr rhs) {
    bool retval = false;
    retval = value_SetStrptrMaybe(parent,rhs); // try symbol conversion
    if (!retval) { // didn't work? try reading as underlying type
        retval = u8_ReadStrptrMaybe(parent.value,rhs);
    }
    return retval;
}

// --- kafka.TimestampType..ReadStrptrMaybe
// Read fields of kafka::TimestampType from an ascii string.
// The format of the string is the format of the kafka::TimestampType's only field
bool kafka::TimestampType_ReadStrptrMaybe(kafka::TimestampType &parent, algo::strptr in_str) {
    bool retval = true;
    retval = retval && value_ReadStrptrMaybe(parent, in_str);
    return retval;
}

// --- kafka.TimestampType..Print
// print string representation of ROW to string STR
// cfmt:kafka.TimestampType.String  printfmt:Raw
void kafka::TimestampType_Print(kafka::TimestampType& row, algo::cstring& str) {
    kafka::value_Print(row, str);
}

// --- kafka...SizeCheck
inline static void kafka::SizeCheck() {
}

// --- kafka...StaticCheck
void kafka::StaticCheck() {
    algo_assert(_offset_of(kafka::AclOperationType, value) + sizeof(((kafka::AclOperationType*)0)->value) == sizeof(kafka::AclOperationType));
    // check that bitfield fits width
    algo_assert(sizeof(((kafka::AclOperations*)0)->value)*8 >= 32);
    algo_assert(_offset_of(kafka::AclPermissionType, value) + sizeof(((kafka::AclPermissionType*)0)->value) == sizeof(kafka::AclPermissionType));
    algo_assert(_offset_of(kafka::ConfigSource, value) + sizeof(((kafka::ConfigSource*)0)->value) == sizeof(kafka::ConfigSource));
    algo_assert(_offset_of(kafka::ConfigType, value) + sizeof(((kafka::ConfigType*)0)->value) == sizeof(kafka::ConfigType));
    algo_assert(_offset_of(kafka::FieldId, value) + sizeof(((kafka::FieldId*)0)->value) == sizeof(kafka::FieldId));
    algo_assert(_offset_of(kafka::Frame_curs, msglen) + sizeof(((kafka::Frame_curs*)0)->msglen) == sizeof(kafka::Frame_curs));
    algo_assert(_offset_of(kafka::GroupRecordKeyHeaderMsgsCase, value) + sizeof(((kafka::GroupRecordKeyHeaderMsgsCase*)0)->value) == sizeof(kafka::GroupRecordKeyHeaderMsgsCase));
    algo_assert(_offset_of(kafka::GroupRecordValueHeaderMsgsCase, value) + sizeof(((kafka::GroupRecordValueHeaderMsgsCase*)0)->value) == sizeof(kafka::GroupRecordValueHeaderMsgsCase));
    algo_assert(_offset_of(kafka::GroupState, value) + sizeof(((kafka::GroupState*)0)->value) == sizeof(kafka::GroupState));
    algo_assert(_offset_of(kafka::PatternType, value) + sizeof(((kafka::PatternType*)0)->value) == sizeof(kafka::PatternType));
    algo_assert(_offset_of(kafka::ResourceType, value) + sizeof(((kafka::ResourceType*)0)->value) == sizeof(kafka::ResourceType));
}

// --- kafka.GroupRecordKeyHeaderMsgs..Print
// Print message to STR. If message is too short for MSG_LEN, print nothing.
// MSG.LENGTH must have already been validated against msg_len.
// This function will additionally validate that sizeof(Msg) <= msg_len
bool kafka::GroupRecordKeyHeaderMsgs_Print(algo::cstring &str, kafka::GroupRecordKeyHeader &msg, u32 msg_len) {
    switch(msg.type) {
        case 1: {
            if (sizeof(kafka::OffsetCommitKey) > msg_len) { return false; }
            OffsetCommitKey_Print((kafka::OffsetCommitKey&)(msg), str);
            return true;
        }
        default:

        return false;
    }
}

// --- kafka.GroupRecordValueHeaderMsgs..Print
// Print message to STR. If message is too short for MSG_LEN, print nothing.
// MSG.LENGTH must have already been validated against msg_len.
// This function will additionally validate that sizeof(Msg) <= msg_len
bool kafka::GroupRecordValueHeaderMsgs_Print(algo::cstring &str, kafka::GroupRecordValueHeader &msg, u32 msg_len) {
    switch(msg.type) {
        case 1: {
            if (sizeof(kafka::OffsetCommitValue) > msg_len) { return false; }
            OffsetCommitValue_Print((kafka::OffsetCommitValue&)(msg), str);
            return true;
        }
        default:

        return false;
    }
}

// --- kafka.GroupRecordKeyHeaderMsgs..ReadStrptr
// Parse ascii representation of message into binary, appending new data to BUF.
kafka::GroupRecordKeyHeaderMsgsCase kafka::GroupRecordKeyHeaderMsgs_ReadStrptr(algo::strptr str, algo::ByteAry &buf) {
    bool ok = false;
    tempstr msgtype_str;
    algo::StringIter iter(str);
    cstring_ReadCmdarg(msgtype_str, iter, false); // read first word
    kafka::GroupRecordKeyHeaderMsgsCase msgtype;
    value_SetStrptrMaybe(msgtype, msgtype_str); // map string -> enum
    switch (value_GetEnum(msgtype)) { // what message is it?
        case kafka_GroupRecordKeyHeaderMsgsCase_kafka_OffsetCommitKey: {
            int len = sizeof(kafka::OffsetCommitKey);
            kafka::OffsetCommitKey *ctype = new(ary_AllocN(buf, len).elems) kafka::OffsetCommitKey; // default values
            ok = OffsetCommitKey_ReadStrptrMaybe(*ctype, str); // now read attributes
        } break; // kafka::OffsetCommitKey case

        default: break;
    }
    return ok ? msgtype : kafka::GroupRecordKeyHeaderMsgsCase();
}

// --- kafka.GroupRecordKeyHeaderMsgs..ReadStrptrMaybe
// Parse ascii representation of message into binary, appending new data to BUF.
bool kafka::GroupRecordKeyHeaderMsgs_ReadStrptrMaybe(algo::strptr str, algo::ByteAry &buf) {
    kafka::GroupRecordKeyHeaderMsgsCase msgtype = GroupRecordKeyHeaderMsgs_ReadStrptr(str,buf);
    return !(msgtype == kafka::GroupRecordKeyHeaderMsgsCase());
}

// --- kafka.GroupRecordValueHeaderMsgs..ReadStrptr
// Parse ascii representation of message into binary, appending new data to BUF.
kafka::GroupRecordValueHeaderMsgsCase kafka::GroupRecordValueHeaderMsgs_ReadStrptr(algo::strptr str, algo::ByteAry &buf) {
    bool ok = false;
    tempstr msgtype_str;
    algo::StringIter iter(str);
    cstring_ReadCmdarg(msgtype_str, iter, false); // read first word
    kafka::GroupRecordValueHeaderMsgsCase msgtype;
    value_SetStrptrMaybe(msgtype, msgtype_str); // map string -> enum
    switch (value_GetEnum(msgtype)) { // what message is it?
        case kafka_GroupRecordValueHeaderMsgsCase_kafka_OffsetCommitValue: {
            // no cfmt read:Y found -- cannot read
        } break; // kafka::OffsetCommitValue case

        default: break;
    }
    (void)buf;//only to avoid -Wunused-parameter
    return ok ? msgtype : kafka::GroupRecordValueHeaderMsgsCase();
}

// --- kafka.GroupRecordValueHeaderMsgs..ReadStrptrMaybe
// Parse ascii representation of message into binary, appending new data to BUF.
bool kafka::GroupRecordValueHeaderMsgs_ReadStrptrMaybe(algo::strptr str, algo::ByteAry &buf) {
    kafka::GroupRecordValueHeaderMsgsCase msgtype = GroupRecordValueHeaderMsgs_ReadStrptr(str,buf);
    return !(msgtype == kafka::GroupRecordValueHeaderMsgsCase());
}
